{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a1f355",
   "metadata": {},
   "source": [
    "<p> <center> <a href=\"../Start_Here.ipynb\">Home Page</a> </center> </p>\n",
    "\n",
    " \n",
    "<div>\n",
    "    <span style=\"float: left; width: 33%; text-align: left;\"><a href=\"General_preprocessing.ipynb\">Previous Notebook</a></span>\n",
    "    <span style=\"float: left; width: 33%; text-align: center;\">\n",
    "        <a href=\"Overview.ipynb\">1</a>\n",
    "        <a href=\"General_preprocessing.ipynb\">2</a>\n",
    "        <a >3</a>\n",
    "        <a href=\"Exercise.ipynb\">4</a>\n",
    "        <a href=\"Summary.ipynb\">5</a>\n",
    "    </span>\n",
    "    <span style=\"float: left; width: 33%; text-align: right;\"><a href=\"Exercise.ipynb\">Next Notebook</a></span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0d87a",
   "metadata": {},
   "source": [
    "# Question Answering Text Data Processing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0acab87",
   "metadata": {},
   "source": [
    "## Goal \n",
    "\n",
    "The goal of this notebook is to learn how to create a Question Answering dataset in SQuAD format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6124086d",
   "metadata": {},
   "source": [
    "### SQuAD Dataset  Structural Format\n",
    "\n",
    "The SQuAD dataset is in `JSON` format and contains the `version` of the JSON file and `data`. Within the `data` is the `title` and `paragraphs`. Within the `paragraphs` lies the `qas` and `context`. Details on `qas` and `context` have been discussed in our previous notebook on `overview of QA dataset`. A context is a text extracted from a document. The number of questions and answers `(qa)` in a single context should not exceed 10 to have a good training result. More so, each question should have a unique id, and those with no corresponding answers (whose answers could be difficult to extract from the context) should have the `is_impossible` flag set to `True` and have `plausible_answers`. The extract from SQuAD 2.0 dataset below shows the first title as `Beyonce` and the last title as `Matter`. This is to aid your understanding of the SQuAD 2.0 JSON format. The simplified structural overview is presented in Figure 1.\n",
    "\n",
    "```python\n",
    "{\n",
    "    'version': 'v2.0',\n",
    "         'data': [\n",
    "                   {\n",
    "                   'title': 'Beyoncé',\n",
    "              'paragraphs': [\n",
    "                              {\n",
    "                                'qas': [\n",
    "                                            {\n",
    "                                                'question': 'When did Beyonce start becoming popular?',\n",
    "                                                      'id': '56be85543aeaaa14008c9063',\n",
    "                                                 'answers': [{'text': 'in the late 1990s', 'answer_start': 269}],\n",
    "                                           'is_impossible': False\n",
    "                                            },\n",
    "                                            {\n",
    "                                                'question': 'What areas did Beyonce compete in when she was growing...',\n",
    "                                                      'id': '56be85543aeaaa14008c9065',\n",
    "                                                 'answers': [{'text': 'singing and dancing', 'answer_start': 207}],\n",
    "                                           'is_impossible': False\n",
    "                                            }\n",
    "                                       ], #closing qas list\n",
    "                 \n",
    "                            'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'\n",
    "                             }, \n",
    "                  \n",
    "         .....................................................\n",
    "                          ]# clossing paragraphs\n",
    "                    }, #closing brace before title\n",
    "             \n",
    "                    {# opening title\n",
    "                     'title': 'Matter',\n",
    "              'paragraphs': [{\n",
    "                              'qas': [\n",
    "                                       {\n",
    "                                      'plausible_answers': [{'text': 'ordinary matter composed of atoms',...........}],\n",
    "                                               'question': 'What did the term matter include after the 20th century?',\n",
    "                                                     'id': '5a7db48670df9f001a87505f',\n",
    "                                                'answers': [],\n",
    "                                          'is_impossible': True\n",
    "                                       },\n",
    "                                       {..........................}\n",
    "                                     ]\n",
    "                           'context': .............................\n",
    "                             }, \n",
    "                             {\n",
    "                               'qas': [\n",
    "                                            {\n",
    "                                       'plausible_answers': [{'text': 'matter', 'answer_start': 485}],\n",
    "                                                'question': 'Physics has broadly agreed on the definition of what?',\n",
    "                                                      'id': '5a7e070b70df9f001a875439',\n",
    "                                                 'answers': [],\n",
    "                                           'is_impossible': True\n",
    "                                            },\n",
    "                                            {\n",
    "                                       'plausible_answers': [{'text': 'Alfvén', 'answer_start': 327}],\n",
    "                                                'question': 'Who coined the term partonic matter?',\n",
    "                                                      'id': '5a7e070b70df9f001a87543a',\n",
    "                                                 'answers': [],\n",
    "                                           'is_impossible': True\n",
    "                                            }\n",
    "                                      ], #closing qas list\n",
    "                         'context': 'The term \"matter\" is used throughout physics in a bewildering variety of contexts: for example, one refers to \"condensed matter physics\", \"elementary matter\", \"partonic\" matter, \"dark\" matter, \"anti\"-matter, \"strange\" matter, and \"nuclear\" matter. In discussions of matter and antimatter, normal matter has been referred to by Alfvén as koinomatter (Gk. common matter). It is fair to say that in physics, there is no broad consensus as to a general definition of matter, and the term \"matter\" usually is used in conjunction with a specifying modifier.'\n",
    "                          }#closing last qas & context within paragraph\n",
    "                      ] #closing paragraph\n",
    "                } #closing brace before title\n",
    "            ] #closing data\n",
    "} #closing json brace\n",
    "  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcfa88b",
   "metadata": {},
   "source": [
    "<img src=\"images/squad_format.png\" width=\"800px\" height=\"800px\"/>\n",
    "<center>Figure 1: Simplified SQuAD json format</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce3598",
   "metadata": {},
   "source": [
    "## Basic Text Data Source \n",
    "\n",
    "\n",
    "We are going to consider three different text data sourcing.\r\n",
    "-\tText document (e.g., pdf file)\r\n",
    "-\tAlready mined data from the web\r\n",
    "-\tRaw data scrapping from webpages\r\n",
    "\r\n",
    "A training dataset is generated based on the input data format of the training model. \r\n",
    "\r\n",
    "**Text document**: This could be a file containing either a description or definitions or an essay about a domain/topic. The content is usually in sentences arranged in paragraphs. Each paragraph may form a context which questions and answers can be drawn from. Depending on the choice of the training model input format, the training dataset is generated. The document text does not require further processing for questions and answers to be extracted.\r\n",
    "\r\n",
    "**Already mined data from web**: This type of dataset is usually in Excel format, consisting of several rows and columns and sometimes with missing values within some columns. The data are scrapped from webpages such as Wikipedia, and Amazon, or social media networks like Twitter and Facebook. Through the process of information mining, useful information about entities is extracted from the data and stored in tabular form to map entities to corresponding features. The data sometimes requires a few processing steps to merge each row into a single sentence or paragraph before questions and answers could be extracted.\r\n",
    "\r\n",
    "**Raw data scrapped from webpages**: These types of data are extracted from target web pages. Their raw form usually contains text, images, HTML, and other noises. Text preprocessing techniques are applied to remove unknown characters, symbols, images, and HTML.\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b0d57",
   "metadata": {},
   "source": [
    "<table style=\"border:1px solid black; width:900px\">\n",
    "<tr>\n",
    "    <td style=\"width:330px; height:350px\"><img src=\"images/source_data_doc.png\" width=\"400%px\" height=\"400%\"/></td>\n",
    "    <td style=\" width:330px;height:350px\"><img src=\"images/source_data_excel.png\" width=\"400px\" height=\"400px\"/></td>\n",
    "    </tr><tr>\n",
    "    <td>source: https://www.researchgate.net/publication/ 311301385_Climate_Change </td>\n",
    "    <td>source: https://data.world/promptcloud/amazon- product-dataset-2020 </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td colspan=2 style=\"width:330px;height:270px\"><img src=\"images/source_data_raw.PNG\"  width=\"600px\" height=\"400px\"/></td>\n",
    "    </tr><tr>\n",
    "    <td colspan=2; style=\"text-align:center\"> source: extract from Natural Questions (NQ)  dataset</td>\n",
    "</tr> \n",
    "    \n",
    "<table/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f2bebf",
   "metadata": {},
   "source": [
    "##  Manual QA Generation\n",
    "\n",
    "There are two forms of approach to manually generate question answering:\r\n",
    "\r\n",
    "- On-Code SQuAD format QA dataset generation\r\n",
    "- No-Code SQuAD format QA dataset generation\r\n",
    "\n",
    "\n",
    "\n",
    "### On-Code SQuAD Format QA dataset Genera\n",
    "\n",
    "\n",
    "In this section, we will show you how to use Python code to generate SQuAD format JSON dataset from the three data sources discussed in the previous section above. Question and answer extraction from the text is based on a personal understanding of the text and the intuition of questionable and answerable context from the text. For example, if a text file is given to a group of persons, the questions and answers each individual would extract from the text may slightly differ based on either their understanding of the text or facts they could deduce or spot from the text. During the process of QA extraction, the questions & answers, and the context where they are manually extracted within the text can be formatted in SQuAD format by following the steps below.low. - **Step 1**: create an excel file `(.xlsx)` with three Sheets `(Sheet0, Sheet1, Sheet2. You may rename the sheets as well)`\r\n",
    "- **Step 2**: In Sheet 0, create two columns, one for title ID and the other for Title name as `[tid, title]`. The title represents topics or domains of discussion you want to capture in your QA dataset.\r\n",
    "- **Step 3**: In Sheet 1, create three columns namely `tid` (title id), `cid` (context id), and context. This implies that each context is drawn from a particular topic `(title)` denoted by `tid` and has its unique identifier as `cid`.\r\n",
    "- **Step 4**: In Sheet 2, create four columns namely `tid` (title id), `cid` (context id), question, and answer. Each question and answer is drawn from a context in Sheet1 represented by `cid` (context id) and `tid` (title from which the context was extracted). In a case where the question has no answer that could be drawn from a context then, the answer column is left blank, or `“no-answer”` phrase is written there.\r\n",
    "\r\n",
    "The figure below is a graphical illustration of the 4 steps ove\r\n",
    "bove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed6774",
   "metadata": {},
   "source": [
    "<img src=\"images/excel_sample.png\" width=\"400%px\" height=\"400%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86bbf3",
   "metadata": {},
   "source": [
    "Please note there are other several ways to structure your QA to process into SQuAD JSON format. It is all about the level of complexity your written SQuAD formatting code can handle. It is advisable to simplify as much as possible to avoid mistakes when you are dealing with more than one title with lots of questions and answers.\r\n",
    "\r\n",
    "Run the cell below to format the Excel file shown above to SQuAD forma.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c815a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "path = '../source_code/data/QA_ds.xlsx'\n",
    "xls = pd.ExcelFile(path)\n",
    "\n",
    "Title = pd.read_excel(xls,'Sheet0')\n",
    "Context = pd.read_excel(xls,'Sheet1')\n",
    "QandA   = pd.read_excel(xls,'Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6982d5ed",
   "metadata": {},
   "source": [
    "**View context** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80771b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Context.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc13772",
   "metadata": {},
   "source": [
    "**Display question and answer list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "QandA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ec0307",
   "metadata": {},
   "source": [
    "Run the cell below to build a SQuAD json format dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re, os\n",
    "import pandas as pd\n",
    "\n",
    "class MakeDataset():\n",
    "    def __init__(self, path):\n",
    "        self.Path = path\n",
    "        self.final_json = {}\n",
    "        self.final_json['version'] = \"v2.0\"\n",
    "        self.final_json['data'] = []      \n",
    "    \n",
    "    #read from excel file\n",
    "    def csv_reader(self):\n",
    "        xls = pd.ExcelFile(self.Path)\n",
    "        self.Title = pd.read_excel(xls,'Sheet0')\n",
    "        self.Context = pd.read_excel(xls,'Sheet1')\n",
    "        self.QandA   = pd.read_excel(xls,'Sheet2')\n",
    "        \n",
    "    #get answer location/index range within the context text    \n",
    "    def get_loc(self, answer, content):\n",
    "        loc = re.search(answer.lower(), content.lower())\n",
    "        if loc is None:\n",
    "            return -1\n",
    "        else:\n",
    "            return loc.span()[0]\n",
    "        \n",
    "    # make json format    \n",
    "    def make_json(self):\n",
    "        qid = 1\n",
    "        for i in range(len(self.Title)):\n",
    "            self.brace_in_data ={}\n",
    "            self.brace_in_data['title'] = self.Title['title'][i]\n",
    "            self.brace_in_data['paragraphs'] = []                              \n",
    "            for j in range(len(self.Context)):\n",
    "                if self.Title['tid'][i] == self.Context['tid'][j]:\n",
    "                    brace_in_paragaraphs = {}\n",
    "                    brace_in_paragaraphs['context'] = self.Context['context'][j]\n",
    "                    brace_in_paragaraphs['qas'] = []    \n",
    "                    for k in  range(len(self.QandA)):\n",
    "                        if self.Context['cid'][j] == self.QandA['cid'][k] and self.Title['tid'][i] == self.QandA['tid'][k]:\n",
    "                            brace_in_qas = {}\n",
    "                            brace_in_qas['question'] = self.QandA['question'][k]\n",
    "                            brace_in_qas['id'] = qid\n",
    "                            loc = self.get_loc(self.QandA['answer'][k], self.Context['context'][j])\n",
    "                            if loc == -1:\n",
    "                                brace_in_qas['answer'] =[] \n",
    "                                brace_in_qas['is_impossible'] = True\n",
    "                            else:\n",
    "                                brace_in_qas['answer'] =[{'text':self.QandA['answer'][k], 'answer_start':loc}]\n",
    "                                brace_in_qas['is_impossible'] = False\n",
    "                            qid +=1                                   \n",
    "                            brace_in_paragaraphs['qas'].append(brace_in_qas)\n",
    "                    self.brace_in_data['paragraphs'].append(brace_in_paragaraphs)\n",
    "            self.final_json['data'].append(self.brace_in_data)        \n",
    "                    \n",
    "    def save_json(self, filename):\n",
    "        with open(f\"../source_code/data/{filename}.json\", \"w\") as write_file:\n",
    "            json.dump(self.final_json, write_file, indent=4)\n",
    "            print(\"dataset saved in SQauD json format ....\")\n",
    "    \n",
    "\n",
    "path = '../source_code/data/QA_ds.xlsx' \n",
    "Obj = MakeDataset(path)\n",
    "Obj.csv_reader()\n",
    "Obj.make_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90a142",
   "metadata": {},
   "source": [
    "Run the cell below to save the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be0db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_filename = 'custom_squad' \n",
    "Obj.save_json(save_filename)\n",
    "\n",
    "Obj.final_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ad692",
   "metadata": {},
   "source": [
    "### No-Code SQuAD Format QA dataset Generation with Haystack\n",
    "\n",
    "Haystack is an open-source framework for building search systems that work intelligently over large document collections. The framework supports NLP tasks such as question answering, information retrieval, and summarization. Haystack is a web platform that requires no code to generate a SQuAD JSON format dataset. Steps to generating SQuAD format from your text data are stated as follows:\r\n",
    "\r\n",
    "- Prepare your custom text data in a single column Excel file `.csv` such that in the first row, you have `document_text` written there.\r\n",
    "\n",
    "\n",
    "<img src=\"images/haystack_csv_file.png\" width=\"600px\" height=\"600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb4446c",
   "metadata": {},
   "source": [
    "- Go to https://haystack.deepset.ai/components/annotation and follow the steps below:\r\n",
    "    - sign up by clicking on the `Haystack Annotation Tool` link\r\n",
    "    - click on `create project`\r\n",
    "    - input the project name and click on the `create project button`\r\n",
    "\t- click on the small arrow under the `actions` column\r\n",
    "\t- click on the import menu and select `Document`\r\n",
    "\t- select `CSV Batch Upload` and drag your CSV file onto it\r\n",
    "\t- click on `Documents` \r\n",
    "\t- click on the arrow under the `Actions` column for any text you want to add questions and answers to.\r\n",
    "\t- Highlight a section of the text as the answer and then the question dialog box pops up.\r\n",
    "\t- When you are done with all the questions and answers, click on the `export` menu, and next, click on the `export answers`. In a dropdown menu, select `Export in squad format`.\r\n",
    "\n",
    "\n",
    "<img src=\"images/haystack_1.png\" width=\"1000px\" height=\"700px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1884451",
   "metadata": {},
   "source": [
    "<img src=\"images/haystack_2.png\" width=\"900px\" height=\"700px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e14a109",
   "metadata": {},
   "source": [
    "<img src=\"images/haystack_3.png\" width=\"900px\" height=\"700px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe4fb2",
   "metadata": {},
   "source": [
    "Please run the cell below to view the content of the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file_path = '../source_code/data/QA_ds.csv'\n",
    "cv_file = pd.read_csv(input_file_path)\n",
    "\n",
    "cv_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e499ef",
   "metadata": {},
   "source": [
    "You can run the cell below to see the content of the CSV file converted into SQuAD JSON format. In the generated JSON file, it is noticeable the `title` which is present in the on-code approach is missing.  This is because only one title/domain is considered, there including titles to show the distinction between several titles is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab2e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import json # to read json\n",
    "\n",
    "verbose = 1\n",
    "input_file_path = '../source_code/data/answers.json'   \n",
    "if verbose:\n",
    "    print(\"Reading the json file\")    \n",
    "file = json.loads(open(input_file_path).read())\n",
    "if verbose:\n",
    "    print(\"processing...\")\n",
    "\n",
    "data_row = [row for topic in file['data'] for row in topic['paragraphs']]\n",
    "print(\"total qas & context: \", len(data_row))\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409556df",
   "metadata": {},
   "source": [
    "## Automatic QA Generation\n",
    "\n",
    "Automatic question-answering generation AQAG is based on the use of transformer models to generate questions and answers from a given text. A project on AQAG by `Patil Suraj` is found at `https://github.com/patil-suraj/question_generation`. The project is an open source based on seq-2-seq pre-trained transformer models using a straight-forward end-to-end method. `SQuAD dataset` and `T5 model` were used to develop the project with varying input processing formats. For more information, please visit [patil-suraj/question_generation on Github](https://github.com/patil-suraj/question_generation). The project includes four approaches namely: answer-aware question generation, answer extraction models (AQ), multi-task question-answer question generation (Multitask QA-QG), and end-to-end question generation (answer agnostic). Examples of how to use question generation using transformers by Patil Suraj is given as follows:\r\n",
    "\r\n",
    "First, you must have two pre-requisites installed:\r\n",
    "\r\n",
    "- pip install -U transformers==3.0.0\r\n",
    "\r\n",
    "- python -m nltk.downloader punkt\r\n",
    "\r\n",
    "\r\n",
    "then, pull the `question-answering` repo from GitHub and navigate to the irectory\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a689247",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/patil-suraj/question_generation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('question_generation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a3644",
   "metadata": {},
   "source": [
    "import pipeline from `pipelines.py` via question_generation directory and set contexts. For illustration's sake, we are using two contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8411c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines import pipeline\n",
    "\n",
    "context_1 = 'Climate is the average of the weather conditions at a particular point on the Earth. Typically, climate \\\n",
    "is expressed in terms of expected temperature, rainfall and wind conditions based on historical observations. Climate change \\\n",
    "is a change in either the average climate or climate variability that persists over an extended period.'\n",
    "\n",
    "context_2 = 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer,\\\n",
    "songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing \\\n",
    "competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by \\\n",
    "her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the \\\n",
    "release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned \\\n",
    "five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94560b0",
   "metadata": {},
   "source": [
    "#### Generate questions and answers from context\n",
    "\n",
    "- **Perform a single task QA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7362de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the pipeline object\n",
    "nlp = pipeline(\"question-generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61756c0",
   "metadata": {},
   "source": [
    "Apply `nlp` pipeline on context_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3e08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the pipeline\n",
    "qa1 = nlp(context_1)\n",
    "qa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa2 = nlp(context_2)\n",
    "qa2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd469f4",
   "metadata": {},
   "source": [
    "- **Use the`t5-base` model by setting the path to the model parameter: `model=\"valhalla/t5-base-qg-hl\"`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a01eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the pipeline object\n",
    "nlp = pipeline(\"question-generation\", model=\"valhalla/t5-base-qg-hl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the pipeline\n",
    "nlp(context_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(context_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f3e5f7",
   "metadata": {},
   "source": [
    "### Using Context from the CSV File\n",
    "\n",
    "Let's use the context in the `.csv` file from the section above (`No Code SQuAD Format QA dataset Generation with Haystack`)  as our input source to `nlp` pipeline `pipeline (\"question-generation\", model=\"valhalla/t5-base-qg-hl\")`, and apply the code cells below to generate SQuAD JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re, os\n",
    "\n",
    "#get answer location/index range within the context text  \n",
    "def get_loc(answer, content):\n",
    "    loc = re.search(answer.lower(), content.lower())\n",
    "    if loc is None:\n",
    "        return -1\n",
    "    else:\n",
    "        return loc.span()[0]\n",
    "    \n",
    "#make json format \n",
    "def make_json(qa, context):\n",
    "    qid = 1\n",
    "    final_json = {}\n",
    "    final_json['version'] = \"v2.0\"\n",
    "    final_json['data'] = []\n",
    "    brace_in_data ={}\n",
    "    #self.brace_in_data['title'] = self.Title['title'][i]\n",
    "    brace_in_data['paragraphs'] = []\n",
    "    for j in range(len(context)):\n",
    "        brace_in_paragaraphs = {}\n",
    "        #brace_in_paragaraphs['context'] = context[j]\n",
    "        brace_in_paragaraphs['qas'] = []    \n",
    "        for row in qa[j]:\n",
    "            brace_in_qas = {}\n",
    "            #for row in rows:                \n",
    "            brace_in_qas['question'] = row['question']\n",
    "            brace_in_qas['id'] = qid\n",
    "            loc = get_loc(str(row['answer']), str(context[j]))\n",
    "            if loc == -1:\n",
    "                brace_in_qas['answer'] =[] \n",
    "                brace_in_qas['is_impossible'] = True\n",
    "            else:\n",
    "                brace_in_qas['answer'] =[{'text':row['answer'], 'answer_start':loc}]\n",
    "                brace_in_qas['is_impossible'] = False\n",
    "            qid +=1\n",
    "            brace_in_paragaraphs['qas'].append(brace_in_qas)\n",
    "        brace_in_paragaraphs['context'] = context[j]\n",
    "        brace_in_data['paragraphs'].append(brace_in_paragaraphs)\n",
    "    final_json['data'].append(brace_in_data)\n",
    "    \n",
    "    return final_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff7cbe",
   "metadata": {},
   "source": [
    "- **Build QA SQuAD format dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f3f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_file_path = '../source_code/data/QA_ds.csv' \n",
    "cv_file = pd.read_csv(input_file_path) #read CSV file\n",
    "\n",
    "qa = []\n",
    "for row in cv_file['document_text']:\n",
    "    qa.append(nlp(row)) # calling question-generation model\n",
    "\n",
    "json_data = make_json(qa, cv_file['document_text']) # calling make_json function to build SQuAD json file \n",
    "json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d45b96c",
   "metadata": {},
   "source": [
    "- **Multi-task question answer-question generation (Multitask QA-QG)**\n",
    "\n",
    "Use of light model `\"multitask-qa-qg\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298ba559",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"multitask-qa-qg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(context_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754735a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(context_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d062897",
   "metadata": {},
   "source": [
    "Add `t5-base` model by setting the path to the model parameter as: `model=\"valhalla/t5-base-qa-qg-hl\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d48bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"multitask-qa-qg\", model=\"valhalla/t5-base-qa-qg-hl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_qa_qg1 = nlp(context_1)\n",
    "t5_qa_qg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191493d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_qa_qg2 = nlp(context_2)\n",
    "t5_qa_qg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f652aa",
   "metadata": {},
   "source": [
    "#### End-to-End Question Generation\n",
    "\n",
    "The `\"e2e-qg\"` is a model used to generate questions only from context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3176d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the pipeline object\n",
    "nlp = pipeline(\"e2e-qg\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e311f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the pipeline\n",
    "nlp(context_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(context_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa3172c",
   "metadata": {},
   "source": [
    "Apply t5-base model by setting the path to the model parameter as: `model=\"valhalla/t5-base-e2e-qg\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"e2e-qg\", model=\"valhalla/t5-base-e2e-qg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(context_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b313c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(context_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96dad60",
   "metadata": {},
   "source": [
    "In Summary, we have gone through how to build a `QA` `SQuAD format` dataset from text data using a manual and automatic approach. Next in line is to apply all we have learned from the previous notebooks by going through an `exercise` that would test and cement our understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43384502",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://github.com/patil-suraj/question_generation\n",
    "\n",
    "---\n",
    "## Licensing\n",
    "\n",
    "Copyright © 2022 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9872c6",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style=\"float: left; width: 33%; text-align: left;\"><a href=\"General_preprocessing.ipynb\">Previous Notebook</a></span>\n",
    "    <span style=\"float: left; width: 33%; text-align: center;\">\n",
    "        <a href=\"Overview.ipynb\">1</a>\n",
    "        <a href=\"General_preprocessing.ipynb\">2</a>\n",
    "        <a >3</a>\n",
    "        <a href=\"Exercise.ipynb\">4</a>\n",
    "        <a href=\"Summary.ipynb\">5</a>\n",
    "    </span>\n",
    "    <span style=\"float: left; width: 33%; text-align: right;\"><a href=\"Exercise.ipynb\">Next Notebook</a></span>\n",
    "</div>\n",
    "\n",
    "<p> <center> <a href=\"../Start_Here.ipynb\">Home Page</a> </center> </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
