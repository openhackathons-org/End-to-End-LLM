{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <center> <a href=\"../../Start_Here.ipynb\">Home Page</a> </center> </p>\n",
    "\n",
    " \n",
    "<div>\n",
    "    <span style=\"float: left; width: 33%; text-align: left;\"><a href=\"NeMo_Primer.ipynb\">Previous Notebook</a></span>\n",
    "    <span style=\"float: left; width: 33%; text-align: center;\">\n",
    "        <a href=\"NeMo_Primer.ipynb\">1</a>\n",
    "        <a>2</a>\n",
    "        <a href=\"Multitask_Prompt_and_PTuning.ipynb\">3</a>\n",
    "        <a href=\"demo.ipynb\">4</a>\n",
    "    </span>\n",
    "    <span style=\"float: left; width: 33%; text-align: right;\"><a href=\"Multitask_Prompt_and_PTuning.ipynb\">Next Notebook</a></span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiIOhb7iVC3J"
   },
   "source": [
    "# NeMo Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PucJwfbhVC3L"
   },
   "source": [
    "This tutorial will demonstrate how to train, evaluate, and test two types of models for Question-Answering -\n",
    "1. BERT-like models for Extractive Question-Answering\n",
    "2. Sequence-to-Sequence (S2S) models for Generative Question-Answering (ex. T5/BART-like)\n",
    "\n",
    "\n",
    "## Task Description\n",
    "\n",
    "- Given a context and a natural language query, we want to generate an answer for the query\n",
    "- Depending on how the answer is generated, the task can be broadly divided into two types:\n",
    "    1. Extractive Question Answering\n",
    "    2. Generative Question Answering\n",
    "\n",
    "\n",
    "## Extractive Question-Answering with BERT-like models\n",
    "\n",
    "Given a question and a context, both in natural language, predict the span within the context with a start and end position which indicates the answer to the question.\n",
    "For every word in our training dataset we’re going to predict:\n",
    "- likelihood this word is the start of the span \n",
    "- likelihood this word is the end of the span\n",
    "\n",
    "We are using a BERT encoder with 2 span prediction heads for predicting start and end position of the answer. The span predictions are token classifiers consisting of a single linear layer.\n",
    "\n",
    "### BERT Model for QA\n",
    "\n",
    "The [BERT](https://arxiv.org/pdf/1810.04805.pdf) (Bidirectional Encoder Representations from Transformers) model has made significant breakthroughs in Natural Language Understanding in recent years. For most applications, the model is typically trained in pre-training and fine-tuning. \n",
    "- The BERT core model can be pre-trained on large, generic datasets to generate dense vector representations of input sentence(s). \n",
    "- It can be quickly fine-tuned to perform tasks such as question/answering, sentiment analysis, or named entity recognition.\n",
    "\n",
    "\n",
    "The figure below shows a high-level block diagram of pre-training and fine-tuning BERT for QA.\n",
    "<center><img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/bert-model-625x268.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Question-Answering with Sequence-2-Sequence model\n",
    "\n",
    "Given a question and a context, both in natural language, generate an answer for the question. Unlike the BERT-like models, there is no constraint that the answer should be a span within the context.\n",
    "\n",
    "### BRAT Model\n",
    "\n",
    "[BART](https://arxiv.org/abs/1910.13461) is a denoising autoencoder that uses neural machine translation architecture with a bidirectional encoder as in BERT and a left-to-right decoder as in GPT for pretraining sequence-2-sequence model.\n",
    "During training, BART injects noise into the original text and tends to learn the reconstruction process. For example, In a sequence-to-sequence model, the encoder is fed a corrupted version of the tokens, and the decoder is fed the original tokens. \n",
    "\n",
    "The figure below shows depicts a scenario where a corrupted document (left) is encoded with a bidirectional model, and then the likelihood of the original document (right) is calculated with an autoregressive decoder <i>(source: https://arxiv.org/abs/1910.13461)<i>.\n",
    "\n",
    "<center><img src=\"images/BRAT_example.JPG\"></center>\n",
    "<center>source paper - <i>BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xQBtr0KVC3M"
   },
   "source": [
    "## Stanford Question Answering Dataset (SQuAD)\n",
    "\n",
    "The Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset containing questions from crowdworkers on a set of Wikipedia articles. These questions are answerable within a text paragraph known as context. Answers to a few questions may not exist within the context; therefore, those questions remain unanswerable. The previous version of SQuAD dataset is known `SQuAD 1.1` and contains 100k+ question-answer pairs on 500+ articles. The latest version `(SQuAD 2.0)` combines questions from SQuAD 1.1 with more than 50k unanswerable questions written by crowdworkers in an adversarial manner to look similar to answerable ones. The official `SQuAD 2.0` dataset is split into train, dev, and test. Only the train and dev sets are publicly available. It is distributed under the [CC BY-SA 4.0 license](https://creativecommons.org/licenses/by-sa/4.0/legalcode) and can be downloaded [here](https://rajpurkar.github.io/SQuAD-explorer/). \n",
    "\n",
    "#### Data format\n",
    "\n",
    "- **version**: represents the version of the SQuAD JSON dataset\n",
    "- **data**: contains the actual data that includes titles and `paragraphs`\n",
    "- **title**: represents domain/topic of discussion or documents or webpage title where the text for `paragraphs` are being drawn\n",
    "- **paragraphs**: contains a list of `qas` and `context`\n",
    "- **qas**: defines a list that contains questions `(question)`, a unique id for each question `(id)`, corresponding answers `(answers)` to the questions. If a question is impossible to answer, then the `is_impoosible` flag is set to True; otherwise, it is set to False. In the answers list, the `text` represents the answer to the question, while the `answer_start` denotes the index where the answer starts within the context.\n",
    "- **context**: represents a sentence or group sentences where the answer(s) to the question(s) lies. It is possible for a single context to have one to two or more questions. In the examples above, questions are drawn from a single context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To aid your understanding of the SQuAD 2.0 JSON format, a simplified structural overview is presented below.\n",
    "\n",
    "```python\n",
    "{\n",
    "    'version': 'v2.0',\n",
    "         'data': [\n",
    "                   {\n",
    "                   'title': 'Beyoncé',\n",
    "              'paragraphs': [\n",
    "                              {\n",
    "                                'qas': [\n",
    "                                            {\n",
    "                                                'question': 'When did Beyonce start becoming popular?',\n",
    "                                                      'id': '56be85543aeaaa14008c9063',\n",
    "                                                 'answers': [{'text': 'in the late 1990s', 'answer_start': 269}],\n",
    "                                           'is_impossible': False\n",
    "                                            },\n",
    "                                            {\n",
    "                                                'question': 'What areas did Beyonce compete in when she was growing...',\n",
    "                                                      'id': '56be85543aeaaa14008c9065',\n",
    "                                                 'answers': [{'text': 'singing and dancing', 'answer_start': 207}],\n",
    "                                           'is_impossible': False\n",
    "                                            }\n",
    "                                       ], #closing qas list\n",
    "                 \n",
    "                            'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'\n",
    "                             }, \n",
    "                  \n",
    "         .....................................................\n",
    "                          ]# clossing paragraphs\n",
    "                    }, #closing brace before title\n",
    "             \n",
    "                    {# opening title\n",
    "                     'title': 'Matter',\n",
    "              'paragraphs': [{\n",
    "                              'qas': [\n",
    "                                       {\n",
    "                                      'plausible_answers': [{'text': 'ordinary matter composed of atoms',...........}],\n",
    "                                               'question': 'What did the term matter include after the 20th century?',\n",
    "                                                     'id': '5a7db48670df9f001a87505f',\n",
    "                                                'answers': [],\n",
    "                                          'is_impossible': True\n",
    "                                       },\n",
    "                                       {..........................}\n",
    "                                     ]\n",
    "                           'context': .............................\n",
    "                             }, \n",
    "                             {\n",
    "                               'qas': [\n",
    "                                            {\n",
    "                                       'plausible_answers': [{'text': 'matter', 'answer_start': 485}],\n",
    "                                                'question': 'Physics has broadly agreed on the definition of what?',\n",
    "                                                      'id': '5a7e070b70df9f001a875439',\n",
    "                                                 'answers': [],\n",
    "                                           'is_impossible': True\n",
    "                                            },\n",
    "                                            {\n",
    "                                       'plausible_answers': [{'text': 'Alfvén', 'answer_start': 327}],\n",
    "                                                'question': 'Who coined the term partonic matter?',\n",
    "                                                      'id': '5a7e070b70df9f001a87543a',\n",
    "                                                 'answers': [],\n",
    "                                           'is_impossible': True\n",
    "                                            }\n",
    "                                      ], #closing qas list\n",
    "                         'context': 'The term \"matter\" is used throughout physics in a bewildering variety of contexts: for example, one refers to \"condensed matter physics\", \"elementary matter\", \"partonic\" matter, \"dark\" matter, \"anti\"-matter, \"strange\" matter, and \"nuclear\" matter. In discussions of matter and antimatter, normal matter has been referred to by Alfvén as koinomatter (Gk. common matter). It is fair to say that in physics, there is no broad consensus as to a general definition of matter, and the term \"matter\" usually is used in conjunction with a specifying modifier.'\n",
    "                          }#closing last qas & context within paragraph\n",
    "                      ] #closing paragraph\n",
    "                } #closing brace before title\n",
    "            ] #closing data\n",
    "} #closing json brace\n",
    "  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the needed libraries and models for the Question Answering task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import gc\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from nemo.collections.nlp.models.question_answering.qa_bert_model import BERTQAModel\n",
    "from nemo.collections.nlp.models.question_answering.qa_s2s_model import S2SQAModel\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "pl.seed_everything(42)\n",
    "gc.disable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to set the directory path to store the dataset and the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhPr9Jf_VC3O"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/workspace/data\" # directory for storing datasets\n",
    "WORK_DIR = \"/workspace/results/nemo_question_answering\" # directory for storing trained models, logs\n",
    "script_dir = \"/workspace/source_code/nemo_question_answering\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and preprocess the SQuAD dataset using the `get_squad.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python $script_dir/get_squad.py --destDir $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "[NeMo I 2023-08-14 04:32:25 get_squad:66] /workspace/data/\n",
    "[NeMo I 2023-08-14 04:32:25 get_squad:47] Downloading: https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
    "[NeMo I 2023-08-14 04:32:26 get_squad:47] Downloading: https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
    "[NeMo I 2023-08-14 04:32:27 get_squad:47] Downloading: https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
    "[NeMo I 2023-08-14 04:32:27 get_squad:47] Downloading: https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After execution of the above cell, your data folder will contain a subfolder \"squad\" and will contain four files for training and evaluation\n",
    "\n",
    "```\n",
    "squad  \n",
    "│\n",
    "└───v1.1\n",
    "│   │ -  train-v1.1.json\n",
    "│   │ -  dev-v1.1.json\n",
    "│\n",
    "└───v2.0\n",
    "    │ -  train-v2.0.json\n",
    "    │ -  dev-v2.0.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqKD-wReVC3O"
   },
   "outputs": [],
   "source": [
    "!ls -LR {DATA_DIR}/squad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWymW8e0VC3O"
   },
   "source": [
    "# Configuration\n",
    "\n",
    "To proceed with the QA task, models have to be defined in the config file. The config file has multiple important sections that include:\n",
    "\n",
    "- **model**: All arguments that will relate to the Model - language model, span prediction, optimizer and schedulers, datasets and any other related information\n",
    "- **trainer**: Any argument to be passed to PyTorch Lightning\n",
    "- **exp_manager**: All arguments used for setting up the experiment manager - target directory, name, logger information\n",
    "\n",
    "We will set the path to the default config file `qa_conf.yaml` and edit necessary values for training different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOIWJqQ0VC3P"
   },
   "outputs": [],
   "source": [
    "config_dir = '/workspace/source_code/nemo_question_answering/conf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to print the entire default config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvD-gv-FVC3P"
   },
   "outputs": [],
   "source": [
    "config_path = f'{config_dir}/qa_conf.yaml'\n",
    "print(config_path)\n",
    "config = OmegaConf.load(config_path)\n",
    "print(\"Default Config - \\n\")\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFVcvseOVC3R"
   },
   "source": [
    "### Set dataset config values\n",
    "\n",
    "Important parameters to be set include the path to the train, validation, and text sets; batch size; and the number of training, validation, and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Grb0EeRqVC3R"
   },
   "outputs": [],
   "source": [
    "# if True, model will load features from cache if file is present, or\n",
    "# create features and dump to cache file if not already present\n",
    "config.model.dataset.use_cache = False\n",
    "\n",
    "# indicates whether the dataset has unanswerable questions\n",
    "config.model.dataset.version_2_with_negative = True\n",
    "\n",
    "# indicates whether the dataset is of extractive nature or not\n",
    "# if True, context spans/chunks that do not contain answer are treated as unanswerable \n",
    "config.model.dataset.check_if_answer_in_context = True\n",
    "\n",
    "# set file paths for train, validation, and test datasets\n",
    "config.model.train_ds.file = f\"{DATA_DIR}/squad/v2.0/train-v2.0.json\"\n",
    "config.model.validation_ds.file = f\"{DATA_DIR}/squad/v2.0/dev-v2.0.json\"\n",
    "config.model.test_ds.file = f\"{DATA_DIR}/squad/v2.0/dev-v2.0.json\"\n",
    "\n",
    "# set batch sizes for train, validation, and test datasets\n",
    "config.model.train_ds.batch_size = 8\n",
    "config.model.validation_ds.batch_size = 8\n",
    "config.model.test_ds.batch_size = 8\n",
    "\n",
    "# set number of samples to be used from dataset. setting to -1 uses entire dataset\n",
    "config.model.train_ds.num_samples = 5000\n",
    "config.model.validation_ds.num_samples = 1000\n",
    "config.model.test_ds.num_samples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFWF41VwVC3R"
   },
   "source": [
    "### Set trainer config values\n",
    "\n",
    "These values include the maximum number of epochs, maximum steps, device, accelerator, and trainer strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42yif-GIVC3R"
   },
   "outputs": [],
   "source": [
    "config.trainer.max_epochs = 5\n",
    "config.trainer.max_steps = -1 # takes precedence over max_epochs\n",
    "config.trainer.precision = 16\n",
    "config.trainer.devices = [0] # 0 for CPU, or list of the GPUs to use [0] this tutorial does not support multiple GPUs. If needed please use NeMo/examples/nlp/question_answering/question_answering.py\n",
    "config.trainer.accelerator = \"gpu\"\n",
    "config.trainer.strategy=\"dp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDQzMBlbVC3R"
   },
   "source": [
    "### Set experiment manager config values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxY4rnJBVC3R"
   },
   "outputs": [],
   "source": [
    "config.exp_manager.exp_dir = WORK_DIR\n",
    "config.exp_manager.name = \"QA-SQuAD2\"\n",
    "config.exp_manager.create_wandb_logger=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2_C8reNVC3R"
   },
   "source": [
    "## Training and Testing Models\n",
    "\n",
    "In this section we show how to train and test BERT and BRAT models using the SQuAD dataset. \n",
    "\n",
    "### BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Mf-_rioVC3R"
   },
   "source": [
    "#### Set Model Config Values\n",
    "- `bert-base-based` is set as the pretrained model and also as the tokenizer name.\n",
    "- Set the path to save the output model as `../checkpoints/bert_squad_v2_0.nemo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtlGHzVJVC3R"
   },
   "outputs": [],
   "source": [
    "# set language model and tokenizer to be used\n",
    "# tokenizer is derived from model if a tokenizer name is not provided\n",
    "config.model.language_model.pretrained_model_name = \"bert-base-uncased\"\n",
    "config.model.tokenizer.tokenizer_name = \"bert-base-uncased\"\n",
    "\n",
    "# path where model will be saved\n",
    "config.model.nemo_path = f\"{WORK_DIR}/checkpoints/bert_squad_v2_0.nemo\"\n",
    "\n",
    "config.exp_manager.create_checkpoint_callback = True\n",
    "\n",
    "config.model.optim.lr = 3e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaM7fe8rVC3R"
   },
   "source": [
    "#### Create Trainer and Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukLzGmy9VC3R",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(**config.trainer)\n",
    "model = BERTQAModel(config.model, trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "[NeMo I 2023-08-14 04:32:37 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: None, merges_files: None, special_tokens_dict: {}, and use_fast: False\n",
    "[NeMo I 2023-08-14 04:32:38 qa_processing:106] mean no. of chars in doc: 839.2727272727273\n",
    "[NeMo I 2023-08-14 04:32:38 qa_processing:107] max no. of chars in doc: 1895\n",
    "...\n",
    "[NeMo I 2023-08-14 04:32:39 qa_bert_dataset:115] Preprocessing data into features.\n",
    "  0%|                                                                                                          | 0/5000 [00:00<?, ?it/s]\n",
    "[NeMo I 2023-08-14 04:32:39 qa_bert_dataset:264] *** Example ***\n",
    "[NeMo I 2023-08-14 04:32:39 qa_bert_dataset:265] unique_id: 1000000000\n",
    "[NeMo I 2023-08-14 04:32:39 qa_bert_dataset:266] example_index: 0\n",
    "[NeMo I 2023-08-14 04:32:39 qa_bert_dataset:267] doc_span_index: 0\n",
    "...\n",
    "[NeMo I 2023-08-14 04:32:49 qa_bert_dataset:283] start_position: 49\n",
    "[NeMo I 2023-08-14 04:32:49 qa_bert_dataset:284] end_position: 49\n",
    "[NeMo I 2023-08-14 04:32:49 qa_bert_dataset:285] answer: france\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 505.52it/s]\n",
    "[NeMo I 2023-08-14 04:32:49 qa_bert_dataset:90] Converting dict features into object features\n",
    "\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 554802.12it/s]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZIA69rlVC3R"
   },
   "source": [
    "#### Train, Test, and Save the Model\n",
    "\n",
    "The maximum number of epochs is set to 5, please note that one epoch may take up to 7mins depending on the device. Increasing the maximum number of epochs (`config.trainer.max_epochs = 5`) may give better results but take more execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(model)\n",
    "trainer.test(model)\n",
    "\n",
    "model.save_to(config.model.nemo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "...\n",
    "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
    "...\n",
    "    \n",
    "Testing: 0it [00:00, ?it/s]\n",
    "[NeMo I 2023-08-16 23:06:48 qa_bert_model:140] test exact: 35.0\n",
    "[NeMo I 2023-08-16 23:06:48 qa_bert_model:140] test f1: 37.904761904761905\n",
    "[NeMo I 2023-08-16 23:06:48 qa_bert_model:140] test total: 100.0\n",
    "[NeMo I 2023-08-16 23:06:48 qa_bert_model:140] test HasAns_exact: 77.77777777777777\n",
    "[NeMo I 2023-08-16 23:06:48 qa_bert_model:140] test HasAns_f1: 84.23280423280423\n",
    "[NeMo I 2023-08-16 23:06:48 qa_bert_model:140] test HasAns_total: 45.0\n",
    "[NeMo I 2023-08-16 23:06:48 qa_bert_model:140] test NoAns_exact: 0.0\n",
    "[NeMo I 2023-08-16 23:06:48 qa_bert_model:140] test NoAns_f1: 0.0\n",
    "[NeMo I 2023-08-16 23:06:48 qa_bert_model:140] test NoAns_total: 55.0\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃        Test metric        ┃       DataLoader 0        ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│     test_HasAns_exact     │     77.77777862548828     │\n",
    "│      test_HasAns_f1       │     84.23280334472656     │\n",
    "│     test_HasAns_total     │           45.0            │\n",
    "│     test_NoAns_exact      │            0.0            │\n",
    "│       test_NoAns_f1       │            0.0            │\n",
    "│     test_NoAns_total      │           55.0            │\n",
    "│        test_exact         │           35.0            │\n",
    "│          test_f1          │    37.904762268066406     │\n",
    "│         test_loss         │    11.044330596923828     │\n",
    "│        test_total         │           100.0           │\n",
    "└───────────────────────────┴───────────────────────────┘\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5AIv0SEVC3S"
   },
   "source": [
    "#### Load the Saved Model and Run Inference\n",
    "\n",
    "While running the inference, it is possible to see that not all responses matched the expected output. This is expected because of the limited number of epochs that the model was trained. You can modify the value of `config.trainer.max_epochs = 5` above and retrain to see better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7k5kD6tvVC3S"
   },
   "outputs": [],
   "source": [
    "Bmodel = BERTQAModel.restore_from(config.model.nemo_path)\n",
    "\n",
    "eval_device = [config.trainer.devices[0]] if isinstance(config.trainer.devices, list) else 1\n",
    "Bmodel.trainer = pl.Trainer(\n",
    "    devices=eval_device,\n",
    "    accelerator=config.trainer.accelerator,\n",
    "    precision=16,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "config.exp_manager.create_checkpoint_callback = False\n",
    "exp_dir = exp_manager(Bmodel.trainer, config.exp_manager)\n",
    "output_nbest_file = os.path.join(exp_dir, \"output_nbest_file.json\")\n",
    "output_prediction_file = os.path.join(exp_dir, \"output_prediction_file.json\")\n",
    "\n",
    "all_preds, all_nbest = Bmodel.inference(\n",
    "    config.model.test_ds.file,\n",
    "    output_prediction_file=output_prediction_file,\n",
    "    output_nbest_file=output_nbest_file,\n",
    "    num_samples=10, # setting to -1 will use all samples for inference\n",
    ")\n",
    "\n",
    "for question_id in all_preds:\n",
    "    print(all_preds[question_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "...\n",
    "[NeMo I 2023-08-16 23:07:20 save_restore_connector:247] Model BERTQAModel was successfully restored from /workspace/results/nemo_question_answering/checkpoints/bert_squad_v2_0.nemo.\n",
    "...\n",
    "[NeMo I 2023-08-16 23:07:20 exp_manager:370] Experiments will be logged at /workspace/results/nemo_question_answering/QA-SQuAD2/2023-08-16_21-35-22\n",
    "[NeMo I 2023-08-16 23:07:20 exp_manager:788] TensorboardLogger has been set up\n",
    "\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 394.84it/s]\n",
    "\n",
    "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 124091.83it/s]\n",
    "\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 74764.78it/s]\n",
    "\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11735.60it/s]\n",
    "France\n",
    "10th and 11th centuries\n",
    "Denmark, Iceland and Norway\n",
    "Rollo\n",
    "10th century\n",
    "The Normans\n",
    "Normandy\n",
    "The Normans\n",
    "first half of the 10th century\n",
    "William the Conqueror\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyh0SNiyVC3S"
   },
   "source": [
    "### S2S BART Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sy9IYgVYVC3S"
   },
   "source": [
    "#### Set Model Config Values\n",
    "\n",
    "- `facebook/bart-base` is set as the pretrained model and also as the tokenizer name.\n",
    "- Set the path to save the output model as `../checkpoints/bart_squad_v2_0.nemo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKNmHKV5VC3S"
   },
   "outputs": [],
   "source": [
    "# set language model and tokenizer to be used\n",
    "# tokenizer is derived from model if a tokenizer name is not provided\n",
    "config.model.language_model.pretrained_model_name = \"facebook/bart-base\"\n",
    "config.model.tokenizer.tokenizer_name = \"facebook/bart-base\"\n",
    "\n",
    "# path where model will be saved\n",
    "config.model.nemo_path = f\"{WORK_DIR}/checkpoints/bart_squad_v2_0.nemo\"\n",
    "\n",
    "config.exp_manager.create_checkpoint_callback = True\n",
    "\n",
    "config.model.optim.lr = 5e-5\n",
    "\n",
    "#remove vocab_file from gpt model\n",
    "config.model.tokenizer.vocab_file = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_0glS4yVC3S"
   },
   "source": [
    "#### Create trainer and initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jWyHY1oVC3S",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(**config.trainer)\n",
    "model = S2SQAModel(config.model, trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "[NeMo I 2023-08-14 04:35:28 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: facebook/bart-base, vocab_file: None, merges_files: None, special_tokens_dict: {}, and use_fast: False\n",
    "[NeMo I 2023-08-14 04:35:28 qa_processing:106] mean no. of chars in doc: 839.2727272727273\n",
    "[NeMo I 2023-08-14 04:35:28 qa_processing:107] max no. of chars in doc: 1895\n",
    "[NeMo I 2023-08-14 04:35:28 qa_processing:106] mean no. of chars in doc: 677.5487804878048\n",
    "[NeMo I 2023-08-14 04:35:28 qa_processing:107] max no. of chars in doc: 1782\n",
    "...\n",
    "[NeMo I 2023-08-14 04:35:42 qa_processing:107] max no. of chars in doc: 1364\n",
    "[NeMo I 2023-08-14 04:35:42 qa_processing:106] mean no. of chars in doc: 848.4090909090909\n",
    "[NeMo I 2023-08-14 04:35:42 qa_processing:107] max no. of chars in doc: 1901\n",
    "[NeMo I 2023-08-14 04:35:42 qa_s2s_dataset:103] Preprocessing data into features.\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 512.77it/s]\n",
    "[NeMo I 2023-08-14 04:35:42 qa_s2s_dataset:73] Converting dict features into object features\n",
    "\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 789887.76it/s]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xg-j39b4VC3S"
   },
   "source": [
    "#### Train, Test, and Save the Model\n",
    "\n",
    "The maximum number of epochs is set to 5 (`note that it requires 7mins to complete 1 epoch`), increasing the value may give better result but take more execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocsf0EBDVC3S",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(model)\n",
    "trainer.test(model)\n",
    "\n",
    "model.save_to(config.model.nemo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "...    \n",
    "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
    "...\n",
    " \n",
    "Testing: 0it [00:00, ?it/s]\n",
    "[NeMo I 2023-08-16 21:50:01 qa_s2s_model:114] test exact: 29.0\n",
    "[NeMo I 2023-08-16 21:50:01 qa_s2s_model:114] test f1: 32.60714285714286\n",
    "[NeMo I 2023-08-16 21:50:01 qa_s2s_model:114] test total: 100.0\n",
    "[NeMo I 2023-08-16 21:50:01 qa_s2s_model:114] test HasAns_exact: 64.44444444444444\n",
    "[NeMo I 2023-08-16 21:50:01 qa_s2s_model:114] test HasAns_f1: 72.46031746031747\n",
    "[NeMo I 2023-08-16 21:50:01 qa_s2s_model:114] test HasAns_total: 45.0\n",
    "[NeMo I 2023-08-16 21:50:01 qa_s2s_model:114] test NoAns_exact: 0.0\n",
    "[NeMo I 2023-08-16 21:50:01 qa_s2s_model:114] test NoAns_f1: 0.0\n",
    "[NeMo I 2023-08-16 21:50:01 qa_s2s_model:114] test NoAns_total: 55.0\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃        Test metric        ┃       DataLoader 0        ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│     test_HasAns_exact     │     64.44444274902344     │\n",
    "│      test_HasAns_f1       │     72.46031951904297     │\n",
    "│     test_HasAns_total     │           45.0            │\n",
    "│     test_NoAns_exact      │            0.0            │\n",
    "│       test_NoAns_f1       │            0.0            │\n",
    "│     test_NoAns_total      │           55.0            │\n",
    "│        test_exact         │           29.0            │\n",
    "│          test_f1          │     32.60714340209961     │\n",
    "│         test_loss         │    2.6404690742492676     │\n",
    "│        test_total         │           100.0           │\n",
    "└───────────────────────────┴───────────────────────────┘\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vs3pl0VMVC3S"
   },
   "source": [
    "### Load the saved model and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoW6_GO_VC3S"
   },
   "outputs": [],
   "source": [
    "S2S_model = S2SQAModel.restore_from(config.model.nemo_path)\n",
    "\n",
    "eval_device = [config.trainer.devices[0]] if isinstance(config.trainer.devices, list) else 1\n",
    "S2S_model.trainer = pl.Trainer(\n",
    "    devices=eval_device,\n",
    "    accelerator=config.trainer.accelerator,\n",
    "    precision=16,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "config.exp_manager.create_checkpoint_callback = False\n",
    "exp_dir = exp_manager(S2S_model.trainer, config.exp_manager)\n",
    "output_nbest_file = os.path.join(exp_dir, \"output_nbest_file.json\")\n",
    "output_prediction_file = os.path.join(exp_dir, \"output_prediction_file.json\")\n",
    "\n",
    "all_preds, all_nbest = S2S_model.inference(\n",
    "    config.model.test_ds.file,\n",
    "    output_prediction_file=output_prediction_file,\n",
    "    output_nbest_file=output_nbest_file,\n",
    "    num_samples=10, # setting to -1 will use all samples for inference\n",
    ")\n",
    "\n",
    "for question_id in all_preds:\n",
    "    print(all_preds[question_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While running the inference, it is possible to see that not all responses matched the expected output. You can modify the value of `config.trainer.max_epochs = 5` above and retrain to see better results. Note that this step will take more time to get executed\n",
    "\n",
    "##### Expected Output\n",
    "```python\n",
    "...\n",
    "[NeMo I 2023-08-16 21:50:26 save_restore_connector:247] Model S2SQAModel was successfully restored from /workspace/results/nemo_question_answering/checkpoints/bart_squad_v2_0.nemo.\n",
    "...\n",
    "[NeMo I 2023-08-16 21:50:26 exp_manager:370] Experiments will be logged at /workspace/results/nemo_question_answering/QA-SQuAD2/2023-08-16_21-35-22\n",
    "[NeMo I 2023-08-16 21:50:26 exp_manager:788] TensorboardLogger has been set up\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 362.05it/s]\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 59918.63it/s]\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 76121.67it/s]\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 60349.70it/s]\n",
    "France\n",
    "the 10th and 11th centuries\n",
    "Denmark, Iceland and Norway\n",
    "Rollo\n",
    "the 10th century\n",
    "The Normans\n",
    "Normans\n",
    "the Normans\n",
    "first half of the 10th century\n",
    "William the Conqueror\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on Custom Sample Dataset in SQuAD Format\n",
    "\n",
    "In this section, we will create new test data for inferencing. The essence is to measure how well our trained model behaves in the presence of unseen data. The test data consists of two contexts with questions only. The answers are deducible from the context. It is expected that both the BERT model and the BRAT model should be able to answer at least 80% of the questions correctly. After running the cells below, you can modify the questions or both the context and question and rerun the cells to see the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a sample dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Sample dataset content\n",
    "dataset = {\n",
    "  \"version\": \"1.0\",\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"title\": \"This is a sample custom dataset\",\n",
    "      \"paragraphs\": [\n",
    "        {\n",
    "          \"context\": \"In 2010 the Amazon rainforest experienced another severe drought, in some ways more extreme than the 2005 drought. \\\n",
    "          The affected region was approximately 1,160,000 square miles (3,000,000 km2) of rainforest, compared to 734,000 square miles (1,900,000 km2) \\\n",
    "          in 2005. The 2010 drought had three epicenters where vegetation died off, whereas in 2005 the drought was focused on the southwestern part. \\\n",
    "          The findings were published in the journal Science. In a typical year the Amazon absorbs 1.5 gigatons of carbon dioxide; during 2005 instead \\\n",
    "          5 gigatons were released and in 2010 8 gigatons were released.\",\n",
    "          \"qas\": [\n",
    "            {\n",
    "              \"question\": \"How many gigatons of carbon are absorbed by the Amazon in a typical year?\",\n",
    "              \"id\": \"q1\"\n",
    "            },\n",
    "            {\n",
    "              \"question\": \"What was the affected region by the drought in 2010 approximately?\",\n",
    "              \"id\": \"q2\"\n",
    "            },\n",
    "            {\n",
    "              \"question\": \"What were the findings regarding the droughts published in?\",\n",
    "              \"id\": \"q3\"\n",
    "            },\n",
    "            {\n",
    "              \"question\": \"How many gigatons of carbon were released during the 2005 drought?\",\n",
    "              \"id\": \"q4\"\n",
    "            },\n",
    "            {\n",
    "              \"question\": \"How did the 2010 drought differ from the 2005 drought in terms of epicenters?\",\n",
    "              \"id\": \"q5\"\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "          {\n",
    "          \"context\": \"The sun is a massive ball of hot, glowing gases at the center of our solar system. It provides light, heat, and energy that sustains \\\n",
    "          life on Earth. The sun's surface temperature is around 5,500 degrees Celsius (9,932 degrees Fahrenheit), while its core temperature reaches about \\\n",
    "          15 million degrees Celsius (27 million degrees Fahrenheit). The sun's energy is generated through a process called nuclear fusion, where hydrogen \\\n",
    "          atoms combine to form helium, releasing immense amounts of energy in the process.\",\n",
    "          \"qas\": [\n",
    "            {\n",
    "              \"question\": \"What is the approximate surface temperature of the sun?\",\n",
    "              \"id\": \"q6\"\n",
    "            },\n",
    "            {\n",
    "              \"question\": \"How does the sun generate its energy?\",\n",
    "              \"id\": \"q7\"\n",
    "            },\n",
    "            {\n",
    "              \"question\": \"What is the core temperature of the sun?\",\n",
    "              \"id\": \"q8\"\n",
    "            },\n",
    "            {\n",
    "              \"question\": \"What process is responsible for the sun's energy generation, where hydrogen atoms combine to form helium?\",\n",
    "              \"id\": \"q9\"\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "# Save the dataset as a JSON file\n",
    "output_file = f\"{DATA_DIR}/squad/sample_dataset.json\"\n",
    "with open(output_file, \"w\") as json_file:\n",
    "    json.dump(dataset, json_file, indent=4)\n",
    "\n",
    "print(f\"Dataset saved as '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify the Config file\n",
    "\n",
    "Replace the path of the test file in the config file with: `{DATA_DIR}/squad/sample_dataset.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the file path for test dataset\n",
    "config.model.test_ds.file = f\"{DATA_DIR}/squad/sample_dataset.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Run Inference with BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and run inference\n",
    "bert_model = BERTQAModel.restore_from(\"/workspace/results/nemo_question_answering/checkpoints/bert_squad_v2_0.nemo\")\n",
    "eval_device = [config.trainer.devices[0]] if isinstance(config.trainer.devices, list) else 1\n",
    "bert_model.trainer = pl.Trainer(\n",
    "    devices=eval_device,\n",
    "    accelerator=config.trainer.accelerator,\n",
    "    precision=16,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "config.exp_manager.create_checkpoint_callback = False\n",
    "exp_dir = exp_manager(bert_model.trainer, config.exp_manager)\n",
    "bert_output_nbest_file = os.path.join(exp_dir, \"bert_output_nbest_file.json\")\n",
    "bert_output_prediction_file = os.path.join(exp_dir, \"bert_output_prediction_file.json\")\n",
    "\n",
    "all_preds, all_nbest = bert_model.inference(\n",
    "    config.model.test_ds.file,\n",
    "    output_prediction_file=bert_output_prediction_file,\n",
    "    output_nbest_file=bert_output_nbest_file,\n",
    "    num_samples=10, # setting to -1 will use all samples for inference\n",
    ")\n",
    "\n",
    "for question_id in all_preds:\n",
    "    print(all_preds[question_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "```python\n",
    "[NeMo I 2023-08-17 00:07:46 save_restore_connector:247] Model BERTQAModel was successfully restored from /workspace/results/nemo_question_answering/checkpoints/bert_squad_v2_0.nemo.\n",
    "...\n",
    "[NeMo I 2023-08-17 00:07:46 exp_manager:370] Experiments will be logged at /workspace/results/nemo_question_answering/QA-SQuAD2/2023-08-16_21-35-22\n",
    "[NeMo I 2023-08-17 00:07:46 exp_manager:788] TensorboardLogger has been set up\n",
    "\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 475.11it/s]\n",
    "\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 57368.90it/s]\n",
    "\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 35017.38it/s]\n",
    "\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 10163.90it/s]\n",
    "\n",
    "1.5\n",
    "1,160,000 square miles (3,000,000 km2) of rainforest\n",
    "journal Science\n",
    "1.5 gigatons of carbon dioxide; during 2005 instead 5 gigatons were released and in 2010 8\n",
    "more extreme\n",
    "around 5,500 degrees Celsius\n",
    "nuclear fusion\n",
    "15 million degrees Celsius\n",
    "nuclear fusion\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run Inference with S2S BART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and run inference\n",
    "bart_model = S2SQAModel.restore_from(\"/workspace/results/nemo_question_answering/checkpoints/bart_squad_v2_0.nemo\")\n",
    "\n",
    "eval_device = [config.trainer.devices[0]] if isinstance(config.trainer.devices, list) else 1\n",
    "bart_model.trainer = pl.Trainer(\n",
    "    devices=eval_device,\n",
    "    accelerator=config.trainer.accelerator,\n",
    "    precision=16,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "config.exp_manager.create_checkpoint_callback = False\n",
    "exp_dir = exp_manager(bart_model.trainer, config.exp_manager)\n",
    "bart_output_nbest_file = os.path.join(exp_dir, \"bart_output_nbest_file.json\")\n",
    "bart_output_prediction_file = os.path.join(exp_dir, \"bart_output_prediction_file.json\")\n",
    "\n",
    "all_preds, all_nbest = bart_model.inference(\n",
    "    config.model.test_ds.file,\n",
    "    output_prediction_file=bart_output_prediction_file,\n",
    "    output_nbest_file=bart_output_nbest_file,\n",
    "    num_samples=10, # setting to -1 will use all samples for inference\n",
    ")\n",
    "\n",
    "for question_id in all_preds:\n",
    "    print(all_preds[question_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "```python\n",
    "[NeMo I 2023-08-17 00:07:53 save_restore_connector:247] Model S2SQAModel was successfully restored from /workspace/results/nemo_question_answering/checkpoints/bart_squad_v2_0.nemo.\n",
    "...\n",
    "[NeMo I 2023-08-17 00:07:53 exp_manager:370] Experiments will be logged at /workspace/results/nemo_question_answering/QA-SQuAD2/2023-08-16_21-35-22\n",
    "[NeMo I 2023-08-17 00:07:53 exp_manager:788] TensorboardLogger has been set up\n",
    "\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 443.75it/s]\n",
    "\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 57808.17it/s]\n",
    "\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 53773.13it/s]\n",
    "\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 74162.55it/s]\n",
    "\n",
    "1.5\n",
    "1,160,000 square miles\n",
    "journal Science\n",
    "5\n",
    "where vegetation died off\n",
    "5,500\n",
    "nuclear fusion\n",
    "15 million degrees Celsius\n",
    "nuclear fusion\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "To solidify your understanding of this lab, click the `Lab Activity 1` link below to start building your custom model.\n",
    "\n",
    "## <center><div style=\"text-align:center; color:#FF0000; border:3px solid red; height:80px;\"> <b><br/>[Lab Activity 1](Activity1.ipynb)</b> </div> </center>\n",
    "---\n",
    "\n",
    "### Resources\n",
    "Below are resourceful links to guide you and assist you in learning more.\n",
    "- [NeMo Models](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/core.html)\n",
    "- [Core APIs](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/api.html)\n",
    "- [Experiment Manager](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/exp_manager.html)\n",
    "- [Exporting NeMo Models](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/export.html)\n",
    "- [Prompt Learning](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/nemo_megatron/prompt_learning.html)\n",
    "- [NeMo Megatron API](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/api.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licensing\n",
    "Copyright © 2022 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style=\"float: left; width: 33%; text-align: left;\"><a href=\"NeMo_Primer.ipynb\">Previous Notebook</a></span>\n",
    "    <span style=\"float: left; width: 33%; text-align: center;\">\n",
    "         <a href=\"NeMo_Primer.ipynb\">1</a>\n",
    "         <a>2</a>\n",
    "        <a href=\"Multitask_Prompt_and_PTuning.ipynb\">3</a>\n",
    "        <a href=\"demo.ipynb\">4</a>\n",
    "    </span>\n",
    "    <span style=\"float: left; width: 33%; text-align: right;\"><a href=\"Multitask_Prompt_and_PTuning.ipynb\">Next Notebook </a></span>\n",
    "</div>\n",
    "\n",
    "<p> <center> <a href=\"../../Start_Here.ipynb\">Home Page</a> </center> </p>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Question_Answering.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e987a19b1bc60996a600adb5d563aa4a4c022e7b31abb2e65c324714934e8ea9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
