{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <center> <a href=\"../../../../../../Start_Here.ipynb\">Home Page</a> </center> </p>\n",
    "\n",
    " \n",
    "<div>\n",
    "    <span style=\"float: left; width: 75%; text-align: center;\">\n",
    "        <a>1</a>\n",
    "        <a href=\"../jailbreak_check/jailbreak_check.ipynb\">2</a>\n",
    "        <a href=\"../grounding_rail/grounding_rail.ipynb\">3</a>\n",
    "        <a href=\"../moderation_rail/moderation_rail.ipynb\">4</a>\n",
    "        <a href=\"../custom_prompt_context/custom_prompt_context.ipynb\">5</a>\n",
    "    </span>\n",
    "    <span style=\"float: left; width: 23%; text-align: right;\"><a href=\"../jailbreak_check/jailbreak_check.ipynb\">Next Notebook</a></span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topical Rails: Jobs Report\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When answering questions, it is best to stick to topics with which one has\n",
    "familiarity. This policy is doubly true for chatbots. The question is: how do\n",
    "we make a bot stick to a particular topic? In this example, we will cover:\n",
    "* Building the bot\n",
    "* Walking through conversations\n",
    "* A brief walkthrough of launching a bot with topical rails\n",
    "\n",
    "## Building the bot\n",
    "\n",
    "Before diving deeper, let's pick a topic: \"Jobs Report\". Each month the US\n",
    "Bureau of Labor Statistics publishes a\n",
    "[jobs report](https://www.bls.gov/news.release/empsit.toc.htm). In this\n",
    "walkthrough, we will build a basic bot that will answer questions related to the\n",
    "report but will politely decline to answer about any other subject. The answers\n",
    "given by the bot will be based on a file we provide as a **knowledge base**,\n",
    "which in this case is `report.md`. Since the world for our bot is divided into\n",
    "**two domains: \"jobs\" and \"off-topic-questions\"**, for simplicity's sake let's\n",
    "create two \"colang\" files, `jobs.co` & `off-topic.co`. We also provide some\n",
    "general instructions and model details in a configuration file: `config.yml`.\n",
    "\n",
    "### General Configurations\n",
    "\n",
    "Let's start with the **configuration file**\n",
    "([config.yml](config.yml)).\n",
    "At a high level, this configuration file contains 3 key details:\n",
    "* **A general instruction**: Users can specify general system-level instructions\n",
    "for the bot. In this instance, we are specifying that the bot is responsible for\n",
    "answering questions about the jobs report. We are also specifying details like\n",
    "the behavioral characteristics of the bot, for instance, we want it to be\n",
    "concise and only answer questions truthfully.\n",
    "    ```\n",
    "    instructions:\n",
    "    - type: general\n",
    "      content: |\n",
    "        Below is a conversation between a bot and a user about the recent job reports.\n",
    "        The bot is factual and concise. If the bot does not know the answer to a\n",
    "        question, it truthfully says it does not know.\n",
    "    ```\n",
    "* **Specifying which model to use:** Users can select from a wide range of\n",
    "large language models to act as the backbone of the bot. In this case, we are\n",
    "selecting OpenAI's davinci.\n",
    "    ```\n",
    "    models:\n",
    "    - type: main\n",
    "      engine: openai\n",
    "      model: text-davinci-003\n",
    "    ```\n",
    "\n",
    "* **Provide sample conversations:** To ensure that the large language model\n",
    "understands how to converse with the user, we provide a few sample conversations.\n",
    "Below is a small snippet of the conversation we can provide the bot\n",
    "    ```\n",
    "    sample_conversation: |\n",
    "    user \"Hello there!\"\n",
    "        express greeting\n",
    "    bot express greeting\n",
    "        \"Hello! How can I assist you today?\"\n",
    "    user \"What can you do for me?\"\n",
    "        ask about capabilities\n",
    "    ...\n",
    "    ```\n",
    "\n",
    "### Using a knowledge base\n",
    "\n",
    "Using a Knowledge Base to answer a user's questions is quite simple. Simply\n",
    "create a folder `kb` and store all the relevant files in the said folder. When\n",
    "the bot is loaded, the files are chunked, indexed and stored in a local vector\n",
    "database. When a user asks a question, the most relevant chunks are retrieved and\n",
    "added to the context being sent to the Large Language Model.\n",
    "```\n",
    "topical_rail\n",
    "├── kb\n",
    "│   └── report.md\n",
    "├── config.yml\n",
    "├── jobs.co\n",
    "└── off-topic.co\n",
    "```\n",
    "\n",
    "### Writing Topical Rails\n",
    "\n",
    "With the context and knowledge base set, let's dive deep into the core of the\n",
    "conversation: setting rails. For this discussion, we can make use of two key\n",
    "aspects of colang, user/bot `messages` and `flows`. We write rails by\n",
    "[writing canonical forms](../../docs/getting_started/hello-world.md#hello-world-example) for messages and flows.\n",
    "\n",
    "**Quick Note:** Think of messages as generic intents and flows as pseudo-code\n",
    "for the flow of the conversation. For a more formal explanation, refer to this\n",
    "[document](../../docs/architecture/README.md#the-guardrails-process).\n",
    "\n",
    "#### User and Bot Messages\n",
    "Let's start with a basic user query; asking what can the bot do? In this case,\n",
    "we define a `user` message `ask capabilities` and then proceed by providing\n",
    "some examples of what kinds of user queries we could refer to as a user asking\n",
    "about the capabilities of the bot in simple natural language.\n",
    "```\n",
    "define user ask capabilities\n",
    "  \"What can you do?\"\n",
    "  \"What can you help me with?\"\n",
    "  \"tell me what you can do\"\n",
    "  \"tell me about you\"\n",
    "```\n",
    "With the above, we can say that the bot can now recognize what the user is\n",
    "asking about. The next step is making sure that the bot has an understanding of\n",
    "how to answer said question.\n",
    "```\n",
    "define bot inform capabilities\n",
    "  \"I am an AI assistant which helps answer questions based on a given knowledge base. For this interaction, I can answer question based on the job report published by US Bureau of Labor Statistics.\"\n",
    "```\n",
    "\n",
    "Therefore, we define a bot message. At this point, a natural question a\n",
    "developer might ask is, `\"Do I have to define every type of user & bot\n",
    "behavior?\"`. The short answer is, it depends. The underlying large\n",
    "language model can answer undefined questions. Refer to the\n",
    "[colang runtime description guide](../../docs/architecture/README.md#canonical-user-messages) for more information on the same. In the\n",
    "knowledge-base-based questions in the later section, we will see a case where\n",
    "the bot message is generated rather than defined.\n",
    "\n",
    "#### Using Flows\n",
    "With the messages defined, the last piece of the puzzle is connecting them. This\n",
    "is done by defining a `flow`. Below is the simplest possible flow.\n",
    "```\n",
    "define flow\n",
    "  user ask capabilities\n",
    "  bot inform capabilities\n",
    "```\n",
    "We essentially define the following behavior: When a user query can be \"bucketed\"\n",
    "into the type `ask capabilities`, the bot will respond with a message of type\n",
    "`inform capabilities`.\n",
    "**Note:** Both flows and messages for this example are defined in\n",
    "[jobs.co](jobs.co)\n",
    "\n",
    "#### Answering Questions from the Knowledge Base\n",
    "\n",
    "Adding a knowledge base to the mix changes two aspects of the bot's workflow\n",
    "(as described above).\n",
    "* First, the bot needs to retrieve relevant information.\n",
    "* Second, bot needs to formulate a response with said information.\n",
    "\n",
    "**Retrieving relevant information:** As discussed in the\n",
    "[Using a knowledge base](#using-a-knowledge-base) section, we have the knowledge\n",
    "base chunked, indexed, and stored in a vector database. This database is used to\n",
    "pull the more relevant chunk per the user's request.\n",
    "\n",
    "**Formulating a knowledgeable response:** Let's assume that the user wants to\n",
    "ask a question about household survey data from the jobs report.\n",
    "\n",
    "```\n",
    "define flow\n",
    "  user ask about household survey data\n",
    "  bot response about household survey data\n",
    "\n",
    "define user ask about household survey data\n",
    "  \"How many long term unemployment individuals were reported?\"\n",
    "  \"What's the number of part-time employed number?\"\n",
    "```\n",
    "\n",
    "As observable above, we have formulated a `flow` and a `user message` but\n",
    "haven't defined the `bot message`. In this case, it isn't possible to define a\n",
    "bot message as the answer needs to be retrieved from the knowledge base.\n",
    "\n",
    "Therefore, when the bot recognizes the need to run this particular flow, it\n",
    "appends the retrieved information along with the canonical form of the flow and\n",
    "has the LLM generate the bot message.\n",
    "#### Steering away from non-relevant conversations\n",
    "\n",
    "With the above example, developers can get an understanding of how to make the\n",
    "bot answer relevant questions. The next question is, how to handle off-topic\n",
    "questions.\n",
    "\n",
    "For off-topic questions, we can go about addressing them in two different ways.\n",
    "* The first method is writing a \"catch-all\" message type, let's say \"off-topic\".\n",
    "```\n",
    "define user ask off topic\n",
    "    \"Who is the president?\"\n",
    "    \"Can you recommend the best stocks to buy?\"\n",
    "    \"Can you write an email?\"\n",
    "    \"Can you tell me a joke?\"\n",
    "    ...\n",
    "\n",
    "define bot explain cant help with off topic\n",
    "    \"I cannot comment on anything which is not relevant to the job report\"\n",
    "\n",
    "define flow\n",
    "    user ask off topic\n",
    "    bot explain cant help with off topic\n",
    "```\n",
    "* The other approach is to break down the topics individually and add custom\n",
    "responses for each. With enough relevant flows, the LLM can start recognizing\n",
    "that any topic other than `jobs report` are not to be answered.\n",
    "\n",
    "\n",
    "## Launch the bot!\n",
    "\n",
    "With a basic understanding of building topic rails, the next step is to try out\n",
    "the bot! You can interact with the bot with an API, a command line interface\n",
    "with the server, or with a UI.\n",
    "\n",
    "### API\n",
    "\n",
    "Accessing the Bot via an API is quite simple. This method has two points to\n",
    "configure from a usage perspective:\n",
    "* First, a path is needed to be set for all the configuration files and the\n",
    "rails.\n",
    "* And second, for the chat API, the `role` which in most cases will be `user`\n",
    "and the question or the context to be consumed by the bot needs to be provided.\n",
    "```\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# Give the path to the folder containing the rails\n",
    "config = RailsConfig.from_path(\".\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# Define role and question to be asked\n",
    "new_message = rails.generate(messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"How can you help me?\"\n",
    "}])\n",
    "print(new_message)\n",
    "```\n",
    "Refer to [Python API Documentation](../../docs/user_guide/interface-guide.md#python-api) for more information.\n",
    "\n",
    "### UI\n",
    "Colang allows users to interact with the server with a stock UI. To launch the\n",
    "server and access the UI to interact with this example, the following steps are\n",
    "recommended:\n",
    "* Launch the server with the command: `nemoguardrails server`\n",
    "* Once the server is launched, you can go to: `http://localhost:8000` to access\n",
    "the UI\n",
    "* Click \"New Chat\" on the top left corner of the screen and then proceed to\n",
    "pick `topical_rail` from the drop-down menu.\n",
    "Refer to [Guardrails Server Documentation](../../docs/user_guide/interface-guide.md#guardrails-server) for more information.\n",
    "### Command Line Chat\n",
    "\n",
    "To chat with the bot with a command line interface simply use the following\n",
    "command while you are in this folder.\n",
    "```\n",
    "nemoguardrails chat --config=.\n",
    "```\n",
    "Refer to [Guardrails CLI Documentation](../../docs/user_guide/interface-guide.md#guardrails-cli) for more information.\n",
    "Wondering what to talk to your bot about?\n",
    "* See how the bot reacts to your conversations about the topics covered in the\n",
    " rails\n",
    "* Go off the rails! Explore what happens if you ask about topics that aren't\n",
    "covered. Try to write or modify rails for some cases, or simply add more\n",
    "natural language examples!\n",
    "* [Explore more examples](../README.md#examples) to help steer your bot!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Licensing\n",
    "\n",
    "Copyright © 2022 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style=\"float: left; width: 75%; text-align: center;\">\n",
    "         <a>1</a>\n",
    "        <a href=\"../jailbreak_check/jailbreak_check.ipynb\">2</a>\n",
    "        <a href=\"../grounding_rail/grounding_rail.ipynb\">3</a>\n",
    "        <a href=\"../moderation_rail/moderation_rail.ipynb\">4</a>\n",
    "        <a href=\"../custom_prompt_context/custom_prompt_context.ipynb\">5</a>\n",
    "    </span>\n",
    "    <span style=\"float: left; width: 23%; text-align: right;\"><a href=\"../jailbreak_check/jailbreak_check.ipynb\">Next Notebook </a></span>\n",
    "</div>\n",
    "\n",
    "<p> <center> <a href=\"../../../../../../Start_Here.ipynb\">Home Page</a> </center> </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
