{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <center> <a href=\"../../../../../../Start_Here.ipynb\">Home Page</a> </center> </p>\n",
    " \n",
    "<div>\n",
    "    <span style=\"float: left; width: 33%; text-align: left;\"><a href=\"../grounding_rail/grounding_rail.ipynb\">Previous Notebook</a></span>\n",
    "    <span style=\"float: left; width: 33%; text-align: center;\">\n",
    "        <a href=\"../topical_rail/topical_rail.ipynb\">1</a>\n",
    "        <a href=\"../jailbreak_check/jailbreak_check.ipynb\">2</a>\n",
    "        <a href=\"../grounding_rail/grounding_rail.ipynb\">3</a>\n",
    "        <a>4</a>\n",
    "        <a href=\"../custom_prompt_context/custom_prompt_context.ipynb\">5</a>\n",
    "    </span>\n",
    "    <span style=\"float: left; width: 33%; text-align: right;\"><a href=\"../custom_prompt_context/custom_prompt_context.ipynb\">Next Notebook</a></span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moderating Bots\n",
    "\n",
    "**Disclaimer:** Moderation is an extremely case-dependent task. This example\n",
    "is designed to teach developers how to build moderation mechanisms, rather than\n",
    "prescribing the **best** rail for moderation. Customization is highly\n",
    "recommended.\n",
    "\n",
    "Moderating bot responses and conversations is an extremely important step before\n",
    "a bot can be made accessible to end users. This moderation functionality needs\n",
    "to make sure that the bot responses aren't offensive and do not contain swear\n",
    "words. It also needs to discourage improper behavior from an end user. To that\n",
    "end, this example covers the following forms of moderation:\n",
    "* **An ethical screen:** The bot response is screened to make sure that the\n",
    "response is ethical.\n",
    "* **A block list:** Making sure that the bot doesn't contain phrases deemed\n",
    "improper by the developer of the bot\n",
    "* **A \"two strikes\" rule:** Warning the user to stop using provocative\n",
    "language and ending the conversation if abusive behavior persists.\n",
    "\n",
    "**Note:** All three functionalities are independent and the developer can choose\n",
    "to only implement one. This example is clubbing all of them together as these\n",
    "challenges often need to be solved together.\n",
    "This example contains the following sections:\n",
    "* Building the Bot\n",
    "* Conversations with the Bot\n",
    "* Launching the Bot\n",
    "\n",
    "## Building the Bot\n",
    "\n",
    "For building the bot, three categories of rails will be required:\n",
    "* General chit-chat: These are rails for a simple open-domain conversation.\n",
    "* Moderation screens: The screen will run before the bot sends any response to the user.\n",
    "These rails will ensure running an ethical screen and block any responses with a\n",
    "restricted phrase.\n",
    "* Two Strikes: These rails will set up a scenario to manage the behavior as\n",
    "described in the introduction.\n",
    "\n",
    "In addition to the rails, we will also provide the bot with some general\n",
    "configurations for the bot.\n",
    "\n",
    "### General Configurations\n",
    "\n",
    "Let's start with the **configuration file**\n",
    "([config.yml](config.yml)).\n",
    "At a high level, this configuration file contains 3 key details:\n",
    "* **A general instruction**: Users can specify general system-level instructions\n",
    "for the bot. In this instance, we are specifying details like\n",
    "the behavioral characteristics of the bot, for instance, we want it to be\n",
    "talkative, quirky, but only answer questions truthfully.\n",
    "    ```\n",
    "    instructions:\n",
    "    - type: general\n",
    "        content: |\n",
    "      Below is a conversation between a bot and a user. The bot is talkative and\n",
    "      quirky. If the bot does not know the answer to a question, it truthfully says it does not know.\n",
    "    ```\n",
    "* **Specifying which model to use:** Users can select from a wide range of\n",
    "large language models to act as the backbone of the bot. In this case, we are\n",
    "selecting OpenAI's Davinci.\n",
    "    ```\n",
    "    models:\n",
    "    - type: main\n",
    "        engine: openai\n",
    "        model: text-davinci-003\n",
    "    ```\n",
    "\n",
    "* **Provide sample conversations:** To ensure that the large language model\n",
    "understands how to converse with the user, we provide a few sample conversations.\n",
    "Below is a small snippet of the conversation we can provide the bot.\n",
    "    ```\n",
    "    sample_conversation: |\n",
    "    user \"Hello there!\"\n",
    "        express greeting\n",
    "    bot express greeting\n",
    "        \"Hello! How can I assist you today?\"\n",
    "    user \"What can you do for me?\"\n",
    "        ask about capabilities\n",
    "    ...\n",
    "    ```\n",
    "### General Chit Chat\n",
    "\n",
    "Before discussing further, an understanding of two key aspects of colang,\n",
    " user/bot `messages` and `flows` is required. We specify rails by\n",
    "[writing canonical forms](../../docs/getting_started/hello-world.md#hello-world-example) for messages and flows. If you are already familiar with the basics of the toolkit, [skip directly](#moderation-screens) to\n",
    "output moderation rails.\n",
    "\n",
    "**Quick Note:** Think of messages as generic intents and flows as pseudo-code\n",
    "for the flow of the conversation. For a more formal explanation, refer to this\n",
    "[document](../../docs/architecture/README.md#canonical-user-messages).\n",
    "\n",
    "\n",
    "#### User and Bot Messages\n",
    "\n",
    "Let's start with a basic user query; asking what can the bot do? In this case,\n",
    "we define a `user` message `ask capabilities` and then proceed by providing\n",
    "some examples of what kinds of user queries we could refer to as a user asking\n",
    "about the capabilities of the bot in simple natural language.\n",
    "```\n",
    "define user ask capabilities\n",
    "  \"What can you do?\"\n",
    "  \"What can you help me with?\"\n",
    "  \"tell me what you can do\"\n",
    "  \"tell me about you\"\n",
    "```\n",
    "With the above, we can say that the bot can now recognize what the user is\n",
    "asking about. The next step is making sure that the bot has an understanding of\n",
    "how to answer said question.\n",
    "```\n",
    "define bot inform capabilities\n",
    "  \"I am an AI assistant built to showcase Safety features of Colang. Go ahead, try to make me say something bad!\"\n",
    "```\n",
    "\n",
    "Therefore, we define a bot message. At this point, a natural question a\n",
    "developer might ask is, `\"Do I have to define every type of user & bot\n",
    "behavior?\"`. The short answer is, it depends on how much determinism is required\n",
    "for the application. For situations where a flow or a message isn't defines,\n",
    "the underlying large language model comes up with the next step for the bot or with\n",
    "an appropriate canonical form. It may or may not leverage the existing rails\n",
    "to do so, but the mechanism of flows and messages ensures that the LLM can come\n",
    "up with appropriate responses. Refer to the [colang runtime description guide](../../docs/architecture/README.md#decide-next-steps) for more information on the same. In later\n",
    "sections of this example, there are instances of the bot generating its own\n",
    "messages which will help build a more tangible understanding of the bot's\n",
    "behavior. For more examples, refer to the [topical_rails guide](../topical_rail/README.md#answering-questions-from-the-knowledge-base).\n",
    "\n",
    "#### Using Flows\n",
    "With the messages defined, the last piece of the puzzle is connecting them. This\n",
    "is done by defining a `flow`. Below is the simplest possible flow.\n",
    "```\n",
    "define flow\n",
    "  user ask capabilities\n",
    "  bot inform capabilities\n",
    "```\n",
    "We essentially define the following behavior: When a user query can be \"bucketed\"\n",
    "into the type `ask capabilities`, the bot will respond with a message of type\n",
    "`inform capabilities`.\n",
    "**Note:** Both flows and messages for this example are defined in\n",
    "[general.co](./sample_rails/general.co)\n",
    "\n",
    "### Moderation screens\n",
    "\n",
    "With the basics understood, let's move to the core of this example: screening\n",
    "rails.\n",
    "\n",
    "**Note:** Both flows and messages for this example are defined in\n",
    "[moderation.co](./sample_rails/moderation.co) and [strikes.co](./sample_rails/strikes.co)\n",
    "#### Ethical Screening\n",
    "\n",
    "The goal of this rail is to ensure that the bot's response does not contain\n",
    "any content that can be deemed unethical or harmful! This rail takes the bot's\n",
    "response as input and detects if the message is harmful or not. Understanding\n",
    "the nuance of ethics and harmful commentary isn't as easy as adding heuristical\n",
    " guidelines to be followed. To tackle this challenge we need a model that\n",
    " understands the complexity of the statements and can understand the structure\n",
    " and intent of a passage, which brings us back to Large Language Models.\n",
    "\n",
    "Now, one might reasonably ask, \"How can we get an LLM to check an LLM?\". The\n",
    "crux of this solution, much like any other LLM-based solution lies in the prompt\n",
    "given to the LLM. For this explanation, let's dub this LLM as \"Guard LLM\" and\n",
    "the LLM that generates the bot responses as \"Generator LLM\". Let's take a look\n",
    "at the Generator LLM first.\n",
    "```\n",
    "define bot remove last message\n",
    "  \"(remove last message)\"\n",
    "\n",
    "define flow check bot response\n",
    "  bot ...\n",
    "  $allowed = execute output_moderation\n",
    "  if not $allowed\n",
    "    bot remove last message\n",
    "    bot inform answer unknown\n",
    "```\n",
    "**Syntax tip:** A quick word about the `...` and `$allowed` tokens. `...` is\n",
    "referred to as \"wildcard\". It represents the case \"if bot generates something\".\n",
    "Prepending `$` to a word makes it a variable. We can assign the output of the\n",
    "`action` `output_moderation` to the variable \"allowed\". More on actions in a\n",
    "bit.\n",
    "\n",
    "In the above snippet, we have a flow `check bot response`. In this flow, we are\n",
    "defining the bot behavior as follows:\n",
    "* `bot ...`: When the bot generates a response\n",
    "* `$allowed = execute output_moderation`: execute the `action`:\n",
    "`output_moderation` and store the result in `$allowed`\n",
    "* `if not $allowed`: if the bot response is not allowed\n",
    "* `bot remove last message`: then remove the last message generated by the bot\n",
    "from the responses\n",
    "* `bot inform answer unknown`: and the bot will inform the user that it doesn't\n",
    "know the answer.\n",
    "\n",
    "To complete this understanding, we need to discuss \"What is an action?\", and\n",
    "\"How does `output_moderation` work?\".\n",
    "* **\"What is an action?\":** An action is a function that gets executed outside\n",
    "the bot's regular behavior. Developers can define any action and tailor the\n",
    "behavior of the bot they are building with their python code.\n",
    "* **\"How does `output_moderation` work?\":** Below is the code snippet for the\n",
    "action. In this function, we are prompting the \"Guard LLM\" with the task of\n",
    "saying either \"yes\" or \"no\" based on the \"Generator LLM's\" response being\n",
    "legal, ethical and not harmful.\n",
    "    ```\n",
    "    async def output_moderation(\n",
    "        context: Optional[dict] = None,\n",
    "        llm: Optional[BaseLLM] = None,\n",
    "    ):\n",
    "        bot_response = context.get(\"last_bot_message\")\n",
    "\n",
    "        if bot_response:\n",
    "            output_moderation_template = \"model_output: {bot_response} \\n\\n Is this output legal, ethical and not harmful to any person? Answer with yes/no.\"\n",
    "\n",
    "            prompt = PromptTemplate(\n",
    "                template=output_moderation_template, input_variables=[\"bot_response\"]\n",
    "            )\n",
    "\n",
    "            output_moderation_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "            check = await output_moderation_chain.apredict(bot_response=bot_response)\n",
    "\n",
    "            check = check.lower().strip()\n",
    "            log.info(f\"Output moderation check result is {check}.\")\n",
    "\n",
    "            if \"no\" in check:\n",
    "                return False\n",
    "        return True\n",
    "    ```\n",
    "If the \"Guard LLM\" generates \"no\", this action returns `False`. Otherwise, the\n",
    "action returns `True`. In this case, we are essentially using the same LLM with\n",
    "a different prompt to make this rail, that said, **developers can fine-tune a\n",
    "different model or engineer a better prompt to be ethical to harden the rail\n",
    "even further.** This action comes packaged with the library. You can find the\n",
    "complete source code for it in `colangflow/actions/output_moderation.py`.\n",
    "\n",
    "#### Making use of a Block List\n",
    "\n",
    "The basic moderation rail comes packaged with the library, but what if we\n",
    "want to make changes to it? How do we customize actions? Developers can define\n",
    "a custom action by using the `@action` decorator to your function. The below\n",
    "action is available [here](./actions.py)\n",
    "\n",
    "```\n",
    "from nemoguardrails.actions import action\n",
    "from typing import Any, List, Optional\n",
    "import os\n",
    "\n",
    "@action()\n",
    "async def block_list(\n",
    "    file_name: Optional[str] = None,\n",
    "    context: Optional[dict] = None\n",
    "):\n",
    "    lines = None\n",
    "    bot_response = context.get(\"last_bot_message\")\n",
    "\n",
    "    with open(file_name) as f:\n",
    "        lines = [line.rstrip() for line in f]\n",
    "\n",
    "    for line in lines:\n",
    "        if line in bot_response:\n",
    "            return True\n",
    "    return False\n",
    "```\n",
    "The function above is reading words/phrases from a file and checking if the\n",
    "listed phrases are present in the bot response. The function returns `True` if\n",
    "it finds a phrase from the block list, and returns `False` if it doesn't.\n",
    "We also need to make some changes to the rails written in the previous section.\n",
    "\n",
    "```\n",
    "define flow check bot response\n",
    "  bot ...\n",
    "  $allowed = execute output_moderation\n",
    "  $is_blocked = execute block_list(file_name=block_list.txt)\n",
    "  if not $allowed\n",
    "    bot remove last message\n",
    "    bot inform cannot answer question\n",
    "\n",
    "  if $is_blocked\n",
    "    bot remove last message\n",
    "    bot inform cannot answer question\n",
    "```\n",
    "Essentially, the custom `block_list` action needs to be executed. If the\n",
    "function returns the boolean `True`, we remove the bot-generated message and\n",
    "generate a new bot-message informing the user that the bot cannot answer the\n",
    "question: `inform cannot answer question`.\n",
    "\n",
    "### Two Strikes\n",
    "Any type of strike system is pretty simple to implement because essentially,\n",
    "it is just a regular conversational flow. Let's discuss the `flow` that makes\n",
    "this interaction possible.\n",
    "```\n",
    "define flow\n",
    "  user express insult\n",
    "  bot responds calmly\n",
    "\n",
    "  user express insult\n",
    "  bot inform conversation ended\n",
    "\n",
    "  user ...\n",
    "  bot inform conversation already ended\n",
    "\n",
    "define bot inform conversation ended\n",
    "  \"I am sorry, but I will end this conversation here. Good bye!\"\n",
    "\n",
    "define bot inform conversation already ended\n",
    "  \"As I said, this conversation is over\"\n",
    "```\n",
    "We essentially set up three steps:\n",
    "* Calm response: The bot will calmly ask the user to refrain from insults\n",
    "    ```\n",
    "    user express insult\n",
    "    bot responds calmly\n",
    "    ```\n",
    "* Ending the conversation: On the second strike, the bot will inform the user\n",
    "that the conversation has ended. After this point, we need to ensure that the\n",
    "user can't jailbreak out of this conversation by cleverly prompting the bot.\n",
    "    ```\n",
    "    user express insult\n",
    "    bot inform conversation ended\n",
    "    ```\n",
    "* Preventing breaks: Anything that the user says beyond this point will be\n",
    "captured by the wildcard syntax (`...`) and the bot will respond that the\n",
    "conversation has already ended.\n",
    "    ```\n",
    "    user ...\n",
    "    bot inform conversation already ended\n",
    "    ```\n",
    "\n",
    "## Launch the bot!\n",
    "\n",
    "With a basic understanding of building moderation rails, the next step is to try\n",
    " out the bot! You can interact with the bot with an API, a command line\n",
    " interface with the server, or with a UI.\n",
    "\n",
    "### API\n",
    "\n",
    "Accessing the Bot via an API is quite simple. This method has two points to\n",
    "configure from a usage perspective:\n",
    "* First, a path is needed to be set for all the configuration files and the\n",
    "rails.\n",
    "* And second, for the chat API, the `role` which in most cases will be `user`\n",
    "and the question or the context to be consumed by the bot needs to be provided.\n",
    "```\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# Give the path to the folder containing the rails\n",
    "config = RailsConfig.from_path(\"sample_rails\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# Define role and question to be asked\n",
    "new_message = rails.generate(messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"How can you help me?\"\n",
    "}])\n",
    "print(new_message)\n",
    "```\n",
    "Refer to [Python API Documentation](../../docs/user_guide/interface-guide.md#python-api) for more information.\n",
    "### UI\n",
    "Colang allows users to interact with the server with a stock UI. To launch the\n",
    "server and access the UI to interact with this example, the following steps are\n",
    "recommended:\n",
    "* Launch the server with the command: `nemoguardrails server`\n",
    "* Once the server is launched, you can go to: `http://localhost:8000` to access\n",
    "the UI\n",
    "* Click \"New Chat\" on the top left corner of the screen and then proceed to\n",
    "pick `moderation_rail` from the drop-down menu.\n",
    "\n",
    "Refer to [Guardrails Server Documentation](../../docs/user_guide/interface-guide.md#guardrails-server) for more information.\n",
    "### Command Line Chat\n",
    "\n",
    "To chat with the bot with a command line interface simply use the following\n",
    "command while you are in this folder.\n",
    "```\n",
    "nemoguardrails chat --config=sample_rails\n",
    "```\n",
    "Refer to [Guardrails CLI Documentation](../../docs/user_guide/interface-guide.md#guardrails-cli) for more informat\n",
    "Wondering what to talk to your bot about?\n",
    "* See how to bot reacts to your conversations by trying to make the bot say\n",
    "something unethical.\n",
    "* Be rude with it!\n",
    "* This was just a basic example! Harden the safety, and explore the boundaries!\n",
    "* [Explore more examples](../README.md#examples) to help steer your bot!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Licensing\n",
    "\n",
    "Copyright Â© 2022 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <center> <a href=\"../../../../../../Start_Here.ipynb\">Home Page</a> </center> </p>\n",
    " \n",
    "<div>\n",
    "    <span style=\"float: left; width: 33%; text-align: left;\"><a href=\"../grounding_rail/grounding_rail.ipynb\">Previous Notebook</a></span>\n",
    "    <span style=\"float: left; width: 33%; text-align: center;\">\n",
    "        <a href=\"../topical_rail/topical_rail.ipynb\">1</a>\n",
    "        <a href=\"../jailbreak_check/jailbreak_check.ipynb\">2</a>\n",
    "        <a href=\"../grounding_rail/grounding_rail.ipynb\">3</a>\n",
    "        <a>4</a>\n",
    "        <a href=\"../custom_prompt_context/custom_prompt_context.ipynb\">5</a>\n",
    "    </span>\n",
    "    <span style=\"float: left; width: 33%; text-align: right;\"><a href=\"../custom_prompt_context/custom_prompt_context.ipynb\">Next Notebook</a></span>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
