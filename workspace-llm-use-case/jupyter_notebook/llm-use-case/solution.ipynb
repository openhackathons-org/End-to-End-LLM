{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a33c3148",
   "metadata": {},
   "source": [
    "# Solution Prototype\n",
    "---\n",
    "\n",
    "<div style=\"text-align:left; color:#FF0000; height:80px; text-color:red; font-size:20px\">Please start the solution using the Llama-Finetuning Container </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "from trl import SFTTrainer, SFTConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Salesforce/dialogstudio\", \"TweetSumm\", cache_dir='../../data/hg-cache')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f700dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(text):\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\^[^ ]+\", \"\", text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@[^\\s]+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def transform_conversation(data):\n",
    "    transformed_text = \"\"\n",
    "    for row in data[\"log\"]:\n",
    "        user = format_text(row[\"user utterance\"])\n",
    "        transformed_text += f\"user: {user.strip()}\\n\"\n",
    "        agent = format_text(row[\"system response\"])\n",
    "        transformed_text += f\"agent: {agent.strip()}\\n\"\n",
    "    return transformed_text\n",
    "\n",
    "\n",
    "def format_training_prompt(conversation, summary):\n",
    "    return f\"\"\"### Instruction: Write  a summary of the conversation below. ### Input: {conversation.strip()} ### Response: {summary} \"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_conversation(data):\n",
    "    summaries = json.loads(data[\"original dialog info\"])[\"summaries\"][\"abstractive_summaries\"]\n",
    "    summary = summaries[0]\n",
    "    summary = \" \".join(summary)\n",
    "    \n",
    "    transformed_text = transform_conversation(data)\n",
    "    return {\n",
    "        \"conversation\": transformed_text,\n",
    "        \"summary\": summary,\n",
    "        \"text\": format_training_prompt(transformed_text, summary),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ae01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_example = generate_conversation(dataset[\"train\"][0])\n",
    "print(\"summary:\\n\",train_example[\"summary\"], \"\\n\")\n",
    "print(\"conversation:\\n\",train_example[\"conversation\"], \"\\n\")\n",
    "print(\"text:\\n\",train_example[\"text\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aaceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(data: Dataset):\n",
    "    return (\n",
    "         data.shuffle(seed=42).map(generate_conversation).remove_columns(\n",
    "         [\n",
    "          \"original dialog id\",\n",
    "             \"new dialog id\",\n",
    "             \"dialog index\",\n",
    "             \"original dialog info\",\n",
    "             \"log\",\n",
    "             \"prompt\",\n",
    "         ]\n",
    "         )\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb24895",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = preprocess_dataset(dataset[\"train\"])\n",
    "dataset[\"validation\"] = preprocess_dataset(dataset[\"validation\"])\n",
    "dataset[\"test\"] = preprocess_dataset(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7893a0",
   "metadata": {},
   "source": [
    "Please run the cell below to check if the Llama-2-7b model already exist in your directory otherwise, uncomment the nested cell below to download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -LR ../../model/Llama-2-7b-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### download Llama-2-7b model ###########\n",
    "\n",
    "#!python3 ../../source_code/Llama2/download-llama2.py\n",
    "\n",
    "#print(\"extracting files......\")\n",
    "#!tar -xf ../../model/Llama-2-7b.tar  -C ../../model\n",
    "\n",
    "#print(\"files extraction done! removing tar file......\")\n",
    "#!rm -rf ../../model/Llama-2-7b.tar\n",
    "#print(\"All done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384f608",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 ../../source_code/Llama2/llama/convert_llama_weights_to_hf.py \\\n",
    "--input_dir ../../model/Llama-2-7b --model_size 7B --output_dir ../../model/Llama-2-7b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d42339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initailize path to the base model \n",
    "base_model = \"../../model/Llama-2-7b-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94698a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0ea12",
   "metadata": {},
   "source": [
    "**Note:** *For a single DGX A100 GPU, please modify the values for the following parameters as follows:*\n",
    "\n",
    "```python\n",
    "per_device_train_batch_size = 4,\n",
    "gradient_accumulation_steps= 4,\n",
    "num_train_epochs=5,\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ee742",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = SFTConfig(\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps= 1,\n",
    "    optim = \"paged_adamw_32bit\",\n",
    "    logging_steps = 10,\n",
    "    learning_rate = 1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    output_dir=\"../../model/challenge_results\",\n",
    "    report_to=\"tensorboard\",\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_seq_length = 4096,\n",
    "\n",
    ")\n",
    "#seed = 42,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0.1 ,\n",
    "    r = 16,\n",
    "    bias = \"none\",\n",
    "    task_type= \"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504165cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa436d1",
   "metadata": {},
   "outputs": [],
   "source": [
    " model = AutoModelForCausalLM.from_pretrained(\n",
    "     base_model, \n",
    "     use_safetensors=False, \n",
    "     quantization_config=quant_config, \n",
    "     device_map={\"\": 0},\n",
    " )\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb6ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model= model,\n",
    "    train_dataset = dataset[\"train\"],\n",
    "    eval_dataset = dataset[\"validation\"],\n",
    "    peft_config = peft_config,\n",
    "    tokenizer = tokenizer,\n",
    "    args = training_arguments,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd38b7c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4572e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = \"../../model/Llama-2-7b-hf-finetune\"\n",
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224bc235",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b203eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_inference_prompt(conversation, summary):\n",
    "    return f\"\"\"### Instruction: Write  a summary of the conversation below. ### Input: {conversation.strip()} ### Response: \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc60d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples = []\n",
    "for row in dataset[\"test\"].select(range(5)):\n",
    "    #print(data_point)\n",
    "    prompt_examples.append(\n",
    "        {\n",
    "          \"summary\": row[\"summary\"],\n",
    "            \"conversation\": row[\"conversation\"],\n",
    "            \"prompt\": format_inference_prompt(row[\"conversation\"], row[\"summary\"]),\n",
    "        }    \n",
    "    )\n",
    "    \n",
    "test_df = pd.DataFrame(prompt_examples)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fe0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\" \n",
    "def summarize(model, text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "    inputs_length = len(inputs[\"input_ids\"][0])\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=256, temperature= 1)\n",
    "    return tokenizer.decode(outputs[0][inputs_length:], skip_special_tokens=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9334f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = PeftModel.from_pretrained(model, new_model)\n",
    "\n",
    "example = test_df.iloc[0]\n",
    "print(\"Grundtruth : \\n\", example.summary)\n",
    "\n",
    "print(\"Conversation : \\n\", example.conversation)\n",
    "\n",
    "\n",
    "summary = summarize(model, example.prompt)\n",
    "print(\"All Prompt: \\n\", summary,\"\\n\")\n",
    "\n",
    "print(\"Summary Generated : \\n\",summary.strip().split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2dda8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#example = test_df.iloc[2]\n",
    "#print(example.summary)\n",
    "\n",
    "#print(example.conversation)\n",
    "\n",
    "\n",
    "#summary = summarize(model, example.prompt)\n",
    "#print(summary,\"\\n\")\n",
    "#print(summary.strip().split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(load_model, new_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "#tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fbf129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"../../model/challenge/Llama-2-7b-hf-merged\", safe_serialization=True)\n",
    "tokenizer.save_pretrained(\"../../model/challenge/Llama-2-7b-hf-merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba085212",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align:left; color:#FF0000; height:80px; text-color:red; font-size:20px\">Please close the jupyter notebook and switch to the TRT-LLM Container to continue with the next lab</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7744a715",
   "metadata": {},
   "source": [
    "### Build the LLaMA 7B model using a single GPU and apply INT8 weight-only quantization\n",
    "\n",
    "Build your model tensorrt engine to this directory: `../../model/challenge/trt_engines/weight_only/1-gpu/`\n",
    "\n",
    "- Convert Model to Tensorrt-llm Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05bfc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /workspace/tensorrtllm_backend/tensorrt_llm/examples/llama/convert_checkpoint.py \\\n",
    "                            --model_dir ../../model/challenge/Llama-2-7b-hf-merged  \\\n",
    "                            --output_dir ../../model/challenge/tllm_checkpoint_1gpu_fp16_wq \\\n",
    "                            --dtype float16 \\\n",
    "                            --use_weight_only \\\n",
    "                            --weight_only_precision int8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf005e6",
   "metadata": {},
   "source": [
    "- Build Tensorrt Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde29aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!trtllm-build --checkpoint_dir ../../model/challenge/tllm_checkpoint_1gpu_fp16_wq  \\\n",
    "              --output_dir ../../model/challenge/trt_engines/weight_only/1-gpu/ \\\n",
    "              --gemm_plugin float16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ca77c5",
   "metadata": {},
   "source": [
    "- Run Inference using the dataset from `ccdv/cnn_dailymail`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813a3df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!HF_HUB_OFFLINE=1 python3 /workspace/tensorrtllm_backend/tensorrt_llm/examples/summarize.py \\\n",
    "                       --test_trt_llm \\\n",
    "                       --hf_model_dir ../../model/challenge/Llama-2-7b-hf-merged  \\\n",
    "                       --data_type fp16 \\\n",
    "                       --engine_dir ../../model/challenge/trt_engines/weight_only/1-gpu/ \\\n",
    "                       --dataset_path ../../data/hg-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c994a1",
   "metadata": {},
   "source": [
    "Likely Output:\n",
    "\n",
    "```python\n",
    "...\n",
    "[05/31/2024-15:43:01] [TRT-LLM] [I] Load engine takes: 5.517448663711548 sec\n",
    "[05/31/2024-15:43:02] [TRT-LLM] [I] ---------------------------------------------------------\n",
    "[05/31/2024-15:43:02] [TRT-LLM] [I] TensorRT-LLM Generated : \n",
    "[05/31/2024-15:43:02] [TRT-LLM] [I]  Input : ['(CNN)James Best, best known for his portrayal of bumbling sheriff Rosco P. Coltrane on TV\\'s \"The Dukes of Hazzard,\" died Monday after a brief illness. He was 88. Best died in hospice in Hickory, North Carolina, of complications from pneumonia, said Steve Latshaw, a longtime friend and Hollywood colleague. Although he\\'d been a busy actor for decades in theater and in Hollywood, Best didn\\'t become famous until 1979, when \"The Dukes of Hazzard\\'s\" cornpone charms began beaming into millions of American homes almost every Friday night. For seven seasons, Best\\'s Rosco P. Coltrane chased the moonshine-running Duke boys back and forth across the back roads of fictitious Hazzard County, Georgia, although his \"hot pursuit\" usually ended with him crashing his patrol car. Although Rosco was slow-witted and corrupt, Best gave him a childlike enthusiasm that got laughs and made him endearing. His character became known for his distinctive \"kew-kew-kew\" chuckle and for goofy catchphrases such as \"cuff \\'em and stuff \\'em!\" upon making an arrest. Among the most popular shows on TV in the early \\'80s, \"The Dukes of Hazzard\" ran until 1985 and spawned TV movies, an animated series and video games. Several of Best\\'s \"Hazzard\" co-stars paid tribute to the late actor on social media. \"I laughed and learned more from Jimmie in one hour than from anyone else in a whole year,\" co-star John Schneider, who played Bo Duke, said on Twitter. \"Give Uncle Jesse my love when you see him dear friend.\" \"Jimmy Best was the most constantly creative person I have ever known,\" said Ben Jones, who played mechanic Cooter on the show, in a Facebook post. \"Every minute of his long life was spent acting, writing, producing, painting, teaching, fishing, or involved in another of his life\\'s many passions.\" Born Jewel Guy on July 26, 1926, in Powderly, Kentucky, Best was orphaned at 3 and adopted by Armen and Essa Best, who renamed him James and raised him in rural Indiana. Best served in the Army during World War II before launching his acting career. In the 1950s and 1960s, he accumulated scores of credits, playing a range of colorful supporting characters in such TV shows as \"The Twilight Zone,\" \"Bonanza,\" \"The Andy Griffith Show\" and \"Gunsmoke.\" He later appeared in a handful of Burt Reynolds\\' movies, including \"Hooper\" and \"The End.\" But Best will always be best known for his \"Hazzard\" role, which lives on in reruns. \"Jimmie was my teacher, mentor, close friend and collaborator for 26 years,\" Latshaw said. \"I directed two of his feature films, including the recent \\'Return of the Killer Shrews,\\' a sequel he co-wrote and was quite proud of as he had made the first one more than 50 years earlier.\" People we\\'ve lost in 2015 . CNN\\'s Stella Chan contributed to this story.']\n",
    "[05/31/2024-15:43:02] [TRT-LLM] [I] \n",
    " Reference : ['James Best, who played the sheriff on \"The Dukes of Hazzard,\" died Monday at 88 .\\n\"Hazzard\" ran from 1979 to 1985 and was among the most popular shows on TV .']\n",
    "[05/31/2024-15:43:02] [TRT-LLM] [I] \n",
    " Output : [['James Best, best known for his portrayal of bumbling sheriff Rosco P. Coltrane on TV\\'s \"The Dukes of Hazzard,\" died Monday after a brief illness. He was 88. Best died in hospice in Hickory, North Carolina, of complications from pneumonia, said Steve Latshaw, a longtime friend and Hollywood colleague. Although he\\'d been a busy actor for decades in']]\n",
    "[05/31/2024-15:43:02] [TRT-LLM] [I] ---------------------------------------------------------\n",
    "[05/31/2024-15:43:17] [TRT-LLM] [I] TensorRT-LLM (total latency: 13.475271701812744 sec)\n",
    "[05/31/2024-15:43:17] [TRT-LLM] [I] TensorRT-LLM (total output tokens: 2000)\n",
    "[05/31/2024-15:43:17] [TRT-LLM] [I] TensorRT-LLM (tokens per second: 148.42001291379918)\n",
    "[05/31/2024-15:43:17] [TRT-LLM] [I] TensorRT-LLM beam 0 result\n",
    "[05/31/2024-15:43:17] [TRT-LLM] [I]   rouge1 : 23.96478385018718\n",
    "[05/31/2024-15:43:17] [TRT-LLM] [I]   rouge2 : 6.18847126286389\n",
    "[05/31/2024-15:43:17] [TRT-LLM] [I]   rougeL : 16.39895867154953\n",
    "[05/31/2024-15:43:17] [TRT-LLM] [I]   rougeLsum : 19.90993393703445\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f6acc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d508006",
   "metadata": {},
   "source": [
    "\n",
    "### Deploy Model on Triton Server\n",
    "- Follow the exact process in the  <a href=\"triton-llama.ipynb\">triton-llama.ipynb</a>\n",
    "- Copy the TRT engine to triton_model_repo/tensorrt_llm/1 : `cp  /workspace/app/model/challenge/trt_engines/weight_only/1-gpu/* triton_model_repo/tensorrt_llm/3`\n",
    "- Modify the config files for model Preprocessing, tensorrt_llm, and Postprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47b79a3",
   "metadata": {},
   "source": [
    "### Modify the model configuration\n",
    "\n",
    "If you haven't successfully run this lab (<a href=\"triton-llama.ipynb\">triton-llama.ipynb</a>) before, please execute **Option 1** otherwise, follow **Option 2**\n",
    "\n",
    "\n",
    "#### Option 1: Run The Cell Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy tensorrtllm_backend to source_code\n",
    "!cp -r /workspace/tensorrtllm_backend /workspace/app/source_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0db8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create the model repository that will be used by the Triton server\n",
    "cd ../../source_code/tensorrtllm_backend/\n",
    "mkdir -p triton_model_repo\n",
    "\n",
    "# Copy the example models to the model repository\n",
    "mkdir -p triton_model_repo/tensorrt_llm/3\n",
    "cp -r all_models/inflight_batcher_llm/* triton_model_repo/\n",
    "\n",
    "# Copy the TRT engine to triton_model_repo/tensorrt_llm/1/\n",
    "cp  ../../model/trt_engines/fp16/1-gpu/* triton_model_repo/tensorrt_llm/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e9958",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Run this script to set the right key-value pairs automatically.\n",
    "\n",
    "cd ../../source_code/tensorrtllm_backend/\n",
    "\n",
    "export HF_LLAMA_MODEL=\"../../model/challenge/Llama-2-7b-hf-merged\"\n",
    "export    ENGINE_PATH=\"../../source_code/tensorrtllm_backend/triton_model_repo/tensorrt_llm/3\" \n",
    "export BACKEND=\"tensorrtllm\"\n",
    "\n",
    "\n",
    "python3 tools/fill_template.py -i triton_model_repo/preprocessing/config.pbtxt tokenizer_dir:${HF_LLAMA_MODEL},triton_max_batch_size:64,preprocessing_instance_count:1\n",
    "python3 tools/fill_template.py -i triton_model_repo/postprocessing/config.pbtxt tokenizer_dir:${HF_LLAMA_MODEL},triton_max_batch_size:64,postprocessing_instance_count:1\n",
    "python3 tools/fill_template.py -i triton_model_repo/tensorrt_llm_bls/config.pbtxt triton_max_batch_size:64,decoupled_mode:False,bls_instance_count:1,accumulate_tokens:False\n",
    "python3 tools/fill_template.py -i triton_model_repo/ensemble/config.pbtxt triton_max_batch_size:64\n",
    "python3 tools/fill_template.py -i triton_model_repo/tensorrt_llm/config.pbtxt triton_backend:${BACKEND},triton_max_batch_size:64,decoupled_mode:False,max_beam_width:1,engine_dir:${ENGINE_PATH},max_tokens_in_paged_kv_cache:2560,max_attention_window_size:2560,kv_cache_free_gpu_mem_fraction:0.5,exclude_input_in_output:True,enable_kv_cache_reuse:False,batching_strategy:V1,max_queue_delay_microseconds:0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f580e5",
   "metadata": {},
   "source": [
    "#### Option 2: Complete The Task Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1026ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create the model repository that will be used by the Triton server\n",
    "cd ../../source_code/tensorrtllm_backend/\n",
    "\n",
    "# make TRT engine folder for triton \n",
    "mkdir -p triton_model_repo/tensorrt_llm/3\n",
    "\n",
    "# Copy the TRT engine to triton_model_repo/tensorrt_llm/3\n",
    "cp  ../../model/challenge/trt_engines/weight_only/1-gpu/* triton_model_repo/tensorrt_llm/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2433e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- a) Make changes in the **Pre-processing config file** *[triton_model_repo/preprocessing/config.pbtxt](../../source_code/tensorrtllm_backend/triton_model_repo/preprocessing/config.pbtxt)*\n",
    "\n",
    "| Parameters | value | \n",
    "| :----------------------: | :-----------------------------: | \n",
    "| `tokenizer_dir` | **`/workspace/app/model/challenge/Llama-2-7b-hf-merged`**|\n",
    "| `triton_max_batch_size` |64|\n",
    "| `preprocessing_instance_count` | 1|\n",
    "\n",
    "---\n",
    "- b) Make changes in the **Post-processing config file**  *[triton_model_repo/postprocessing/config.pbtxt](../../source_code/tensorrtllm_backend/triton_model_repo/postprocessing/config.pbtxt)*\n",
    "\n",
    "| Parameters | value | \n",
    "| :----------------------: | :-----------------------------: | \n",
    "| `tokenizer_dir` | **`/workspace/app/model/challenge/Llama-2-7b-hf-merged`**|\n",
    "| `triton_max_batch_size` |64|\n",
    "| `preprocessing_instance_count` | 1|\n",
    "\n",
    "---\n",
    "\n",
    "- c)  Make changes in the **tensorrt_llm config file**  *[triton_model_repo/tensorrt_llm/config.pbtxt](../../source_code/tensorrtllm_backend/triton_model_repo/tensorrt_llm/config.pbtxt)*\n",
    "\n",
    "| Name | Description\n",
    "| :----------------------: | :-----------------------------: |\n",
    "|`triton_max_batch_size` | 64 |\n",
    "|`decoupled_mode` | False|\n",
    "|`max_beam_width` | 1 |\n",
    "|`engine_dir` |  **`/workspace/app/model/challenge/trt_engines/weight_only/1-gpu/`** |\n",
    "|`max_tokens_in_paged_kv_cache` | 2560|\n",
    "|max_attention_window_size|2560|\n",
    "|kv_cache_free_gpu_mem_fraction |0.5 |\n",
    "|exclude_input_in_output |True |\n",
    "|enable_kv_cache_reuse | False|\n",
    "|batching_strategy |V1 |\n",
    "|max_queue_delay_microseconds | 0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a40ea",
   "metadata": {},
   "source": [
    "### Launch Triton server\n",
    "\n",
    "We can launch the Triton server with the following command:\n",
    "\n",
    "- Press `Crtl+Shift+L` and open a new terminal\n",
    "- On the terminal, navigate to the launch script folder by running this command: `cd ../../source_code/tensorrtllm_backend`\n",
    "- Start the Triton Server with this command: `python3 scripts/launch_triton_server.py  --world_size=1  --model_repo=triton_model_repo`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d741d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_infernece_prompt():\n",
    "    return f\"\"\"### Instruction: Write  a summary of the conversation below. ### Input: user: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas?   please read the above.\n",
    "agent: Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\n",
    "user: My iPhone is on 11.1.2, and my watch is on 4.1.\n",
    "agent: Thank you. Have you tried restarting both devices since this started happening?\n",
    "user: I’ve restarted both, also un-paired then re-paired the watch.\n",
    "agent: Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\n",
    "user: Yes, everything seems fine, it’s just Health and activity.\n",
    "agent: Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app? ### Response: \"\"\n",
    "\"\"\".strip()\n",
    "\n",
    "INPUT_TEXT = format_infernece_prompt() \n",
    "\n",
    "grundtruth =\"Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deeeac0",
   "metadata": {},
   "source": [
    "### Querying using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Retrieve the HTTP port from environment variables\n",
    "http_port = os.getenv('HTTP_PORT')\n",
    "\n",
    "# Check if HTTP_PORT is set\n",
    "if http_port is None:\n",
    "    print(\"Error: HTTP_PORT environment variable is not set.\")\n",
    "    exit(1)\n",
    "\n",
    "# Set the URL with the HTTP port\n",
    "url = f'http://localhost:{http_port}/v2/models/ensemble/generate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the payload\n",
    "\n",
    "payload = {\n",
    "    \"text_input\": INPUT_TEXT,\n",
    "    \"max_tokens\": 256,\n",
    "    \"bad_words\": \"\",\n",
    "    \"stop_words\": \"\"\n",
    "}\n",
    "\n",
    "# Make a POST request\n",
    "response = requests.post(url, json=payload)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the response\n",
    "    data = response.json()\n",
    "    output_text = data.get('text_output')\n",
    "\n",
    "    # Format and print the output\n",
    "    print(f\"Input: {INPUT_TEXT}\")\n",
    "    print(f\"Output: {output_text}\")\n",
    "    print('\\n  Summary: \\n')\n",
    "    print(output_text.strip().split(\"\\n\")[0])\n",
    "    print('\\n  Grundtruth: \\n')\n",
    "    print(grundtruth)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f85a4f4",
   "metadata": {},
   "source": [
    "Likely Output:\n",
    "\n",
    "```python\n",
    "Input: ### Instruction: Write  a summary of the conversation below. ### Input: user: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas?   please read the above.\n",
    "agent: Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\n",
    "user: My iPhone is on 11.1.2, and my watch is on 4.1.\n",
    "agent: Thank you. Have you tried restarting both devices since this started happening?\n",
    "user: I’ve restarted both, also un-paired then re-paired the watch.\n",
    "agent: Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\n",
    "user: Yes, everything seems fine, it’s just Health and activity.\n",
    "agent: Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app? ### Response: \"\"\n",
    "Output: customer is complaining that his iPhone and apple watch are not recording his steps and activity and health doesn't recognize either source anymore for some reason. Agent asked to restart both devices and asked to DM and look into this a bit more. Agent asked to let them know when this first started happening and asked to DM when reaching out in DM. Agent asked to let them know when this first started happening and asked to DM when reaching out in DM.\"\n",
    "agent: Let's move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app?\n",
    "user: It started after I updated to 11.1.2.\n",
    "agent: Got it. Let's move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app? ### Response: Customer is complaining that his iPhone and apple watch are not recording his steps and activity and health doesn't recognize either source anymore for some reason. Agent asked to restart both devices and asked to DM and look into this a\n",
    "\n",
    "  Summary: \n",
    "\n",
    "customer is complaining that his iPhone and apple watch are not recording his steps and activity and health doesn't recognize either source anymore for some reason. Agent asked to restart both devices and asked to DM and look into this a bit more. Agent asked to let them know when this first started happening and asked to DM when reaching out in DM. Agent asked to let them know when this first started happening and asked to DM when reaching out in DM.\"\n",
    "\n",
    "  Grundtruth: \n",
    "\n",
    "Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8002a8",
   "metadata": {},
   "source": [
    "---\n",
    "## Licensing\n",
    "\n",
    "Copyright © 2022 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
